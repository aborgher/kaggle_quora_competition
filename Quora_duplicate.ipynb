{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## da mettere in files\n",
    "# tag_max_freq\n",
    "# tag_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev3 toc-item\"><a href=\"#Create-basic-features\" data-toc-modified-id=\"Create-basic-features-001\"><span class=\"toc-item-num\">0.0.1&nbsp;&nbsp;</span>Create basic features</a></div><div class=\"lev3 toc-item\"><a href=\"#Create-features-after-tagger-(see-tagger-notebook)\" data-toc-modified-id=\"Create-features-after-tagger-(see-tagger-notebook)-002\"><span class=\"toc-item-num\">0.0.2&nbsp;&nbsp;</span>Create features after tagger (see tagger notebook)</a></div><div class=\"lev3 toc-item\"><a href=\"#Create-&quot;external&quot;-features\" data-toc-modified-id=\"Create-&quot;external&quot;-features-003\"><span class=\"toc-item-num\">0.0.3&nbsp;&nbsp;</span>Create \"external\" features</a></div><div class=\"lev3 toc-item\"><a href=\"#Create-bit-features\" data-toc-modified-id=\"Create-bit-features-004\"><span class=\"toc-item-num\">0.0.4&nbsp;&nbsp;</span>Create bit features</a></div><div class=\"lev3 toc-item\"><a href=\"#Some-features-with-word2vec\" data-toc-modified-id=\"Some-features-with-word2vec-005\"><span class=\"toc-item-num\">0.0.5&nbsp;&nbsp;</span>Some features with word2vec</a></div><div class=\"lev3 toc-item\"><a href=\"#Train-Xgboost-model\" data-toc-modified-id=\"Train-Xgboost-model-006\"><span class=\"toc-item-num\">0.0.6&nbsp;&nbsp;</span>Train Xgboost model</a></div><div class=\"lev3 toc-item\"><a href=\"#Bayesian-Optimization\" data-toc-modified-id=\"Bayesian-Optimization-007\"><span class=\"toc-item-num\">0.0.7&nbsp;&nbsp;</span>Bayesian Optimization</a></div><div class=\"lev3 toc-item\"><a href=\"#Make-Submission\" data-toc-modified-id=\"Make-Submission-008\"><span class=\"toc-item-num\">0.0.8&nbsp;&nbsp;</span>Make Submission</a></div><div class=\"lev3 toc-item\"><a href=\"#The-End\" data-toc-modified-id=\"The-End-009\"><span class=\"toc-item-num\">0.0.9&nbsp;&nbsp;</span>The End</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import quoradefs as qd\n",
    "from time import time\n",
    "import gc\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import Counter\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import gensim\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pickle\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6)\n",
      "(2345796, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      "id              404290 non-null int64\n",
      "qid1            404290 non-null int64\n",
      "qid2            404290 non-null int64\n",
      "question1       404290 non-null object\n",
      "question2       404290 non-null object\n",
      "is_duplicate    404290 non-null int64\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "## adjusting the nan value\n",
    "train_df.fillna(\"\", inplace=True)\n",
    "test_df.fillna(\"\", inplace=True)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAEICAYAAADP6odOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRESkg0KBiIiIAAoFIiIi0uH/AUUvdQ/YkRpxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9a891c2128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "is_dup = train_df['is_duplicate'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(is_dup.index, is_dup.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Is Duplicate', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create basic features \n",
    "\n",
    "- word shared\n",
    "- different characters/words length\n",
    "- matching first/second/third/last word\n",
    "- puntualization\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question1, question2 = 'question1', 'question2'\n",
    "qd.create_diff_punteggiatura(train_df, question1, question2)\n",
    "qd.create_diff_punteggiatura(test_df, question1, question2)\n",
    "\n",
    "qd.add_clear_first(train_df, question1)\n",
    "qd.add_clear_first(train_df, question2)\n",
    "qd.add_clear_first(test_df, question1)\n",
    "qd.add_clear_first(test_df, question2)\n",
    "\n",
    "question1_tagg = question1 + '_clear_1'\n",
    "question2_tagg = question2 + '_clear_1'\n",
    "\n",
    "qd.add_clear_second(train_df, question1_tagg)\n",
    "qd.add_clear_second(train_df, question2_tagg)\n",
    "\n",
    "q1 = 'question1_clear_1_clear_2'\n",
    "q2 = 'question2_clear_1_clear_2'\n",
    "\n",
    "qd.create_add_vars(train_df, q1=q1, q2=q2)\n",
    "qd.calc_match_capital(train_df, question1=q1, question2=q1)\n",
    "\n",
    "qd.calc_match_capital(test_df, question1=q1, question2=q1)\n",
    "qd.create_add_vars(test_df, q1=q1, q2=q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_unique_quests = set(\n",
    "    list(set(train_df[q1])) + list(set(train_df[q2])) + list(set(test_df[q1]))\n",
    "    + list(set(test_df[q2])))\n",
    "all_words = qd.flatmap(qd.get_words, all_unique_quests)\n",
    "cnt_words = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_unique_quests = list(\n",
    "    set(\n",
    "        list(set(train_df[q1])) + list(set(train_df[q2])) +\n",
    "        list(set(test_df[q1])) + list(set(test_df[q2]))))\n",
    "qcat = pd.Series(\n",
    "    list(map(lambda x: (x.split()[0].lower()), list(\n",
    "        all_unique_quests)))).value_counts()\n",
    "qcat = (1 / (qcat)).to_dict()\n",
    "\n",
    "qd.add_first_unique(train_df)\n",
    "qd.add_first_unique(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features after tagger (see tagger notebook)\n",
    "\n",
    "- matching verbds, nouns, etc.\n",
    "- rarity: different class of rarity\n",
    "\n",
    "- sequences: matching structure of the phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "work = pd.read_csv('tagged_list_counted_solved.csv', encoding='latin1', sep=';')\n",
    "\n",
    "sym = work[work['tag_recod']=='SYM']\n",
    "fw = work[work['tag_recod']=='FW']\n",
    "uh = work[work['tag_recod']=='UH']\n",
    "mo = work[work['tag_recod']=='MO']\n",
    "noun = work[work['tag_recod']=='NOUN']\n",
    "verb = work[work['tag_recod']=='VERB']\n",
    "jj = work[work['tag_recod']=='JJ']\n",
    "\n",
    "listverb = Counter(list(verb['name'].values))\n",
    "listsym = Counter(list(sym['name'].values))\n",
    "listuh = Counter(list(uh['name'].values))\n",
    "listfw = Counter(list(fw['name'].values))\n",
    "listnoun = Counter(list(noun['name'].values))\n",
    "listjj = Counter(list(jj['name'].values))\n",
    "listmo = Counter(list(mo['name'].values))\n",
    "\n",
    "tag_list_vars = {\n",
    "    '_VERB': listverb,\n",
    "    '_NOUN': listnoun,\n",
    "    '_FW': listfw,\n",
    "    '_SYM': listsym,\n",
    "    '_MO': listmo,\n",
    "    '_JJ': listjj,\n",
    "    '_UH': listuh\n",
    "}\n",
    "\n",
    "tag_rare_vars = {}\n",
    "for cut in [(0,10), (10,50), (50,100), (100, 1000)]:\n",
    "    tag_rare_vars[str(cut[0]) + '_' + str(cut[1])] = {\n",
    "        '_VERB': Counter(list(verb[ (verb['count'] > cut[0]) & (verb['count']<= cut[1]) ]['name'].values)),\n",
    "        '_NOUN': Counter(list(noun[ (noun['count'] > cut[0]) & (noun['count']<= cut[1]) ]['name'].values)),\n",
    "        '_FW': Counter(list(fw[ (fw['count'] > cut[0]) & (fw['count']<= cut[1]) ]['name'].values)),\n",
    "        '_JJ': Counter(list(jj[ (jj['count'] > cut[0]) & (jj['count']<= cut[1]) ]['name'].values))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tag_var in tag_list_vars.keys():\n",
    "    train_df['count'+tag_var] = train_df.apply(axis=1, func = lambda x:\n",
    "                                                      abs(qd.countword(x[q1], tag_list_vars[tag_var])\n",
    "                                                          - qd.countword(x[q2], tag_list_vars[tag_var])))\n",
    "    \n",
    "for tag_var in tag_list_vars.keys():\n",
    "    test_df['count'+tag_var] = test_df.apply(axis=1, func = lambda x:\n",
    "                                                      abs(qd.countword(x[q1], tag_list_vars[tag_var])\n",
    "                                                          - qd.countword(x[q2], tag_list_vars[tag_var])))\n",
    "    \n",
    "for cut in tag_rare_vars.keys():\n",
    "    for tag_var in tag_rare_vars[cut]:\n",
    "        train_df['rare'+cut +tag_var] = train_df.apply(axis=1, func = lambda x:\n",
    "                                                      abs(qd.countword(x[q1], tag_rare_vars[cut][tag_var])\n",
    "                                                          - qd.countword(x[q2], tag_rare_vars[cut][tag_var])))\n",
    "        \n",
    "for cut in tag_rare_vars.keys():\n",
    "    for tag_var in tag_rare_vars[cut]:\n",
    "        test_df['rare'+cut +tag_var] = test_df.apply(axis=1, func = lambda x:\n",
    "                                                      abs(qd.countword(x[q1], tag_rare_vars[cut][tag_var])\n",
    "                                                          - qd.countword(x[q2], tag_rare_vars[cut][tag_var])))\n",
    "        \n",
    "cut = '100_1000'\n",
    "for tag_var in tag_rare_vars[cut]:\n",
    "    train_df['rare'+cut +tag_var] = train_df.apply(axis=1, func = lambda x:\n",
    "                                                 abs(qd.countword(x[q1], tag_rare_vars[cut][tag_var])\n",
    "                                                     - qd.countword(x[q2], tag_rare_vars[cut][tag_var])))\n",
    "    \n",
    "cut = '100_1000'\n",
    "for tag_var in tag_rare_vars[cut]:\n",
    "    test_df['rare'+cut +tag_var] = test_df.apply(axis=1, func = lambda x:\n",
    "                                                 abs(qd.countword(x[q1], tag_rare_vars[cut][tag_var])\n",
    "                                                     - qd.countword(x[q2], tag_rare_vars[cut][tag_var])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listona_tag = [\n",
    "    'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN',\n",
    "    'NNS', 'NP', 'NPS', 'PDT', 'POS', 'PP', 'PP$', 'RB', 'RBR', 'RBS', 'RP',\n",
    "    'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP',\n",
    "    'WP$', 'WRB'\n",
    "]\n",
    "\n",
    "for tag in listona_tag:\n",
    "    train_df[tag + '_diff'] = train_df.apply(\n",
    "        axis=1, func=lambda x: abs(dizionario.get(x[q1], 'ciccia')[tag] - dizionario.get(x[q2], 'ciccia')[tag]))\n",
    "    \n",
    "for tag in listona_tag:\n",
    "    test_df[tag + '_diff'] = test_df.apply(\n",
    "        axis=1, func=lambda x: abs(dizionario.get(x[q1], 'ciccia')[tag] - dizionario.get(x[q2], 'ciccia')[tag]))\n",
    "\n",
    "dizionario_max = qd.load_obj('tag_max_freq')\n",
    "\n",
    "for i in ['JJ', 'FW', 'VERB', 'NOUN', 'SYM', 'MD', 'WRB', 'IN']:\n",
    "    qd.calc_match_capital2(train_df, q1, q2, diz=dizionario_max, tipo=i)\n",
    "    \n",
    "for i in ['JJ', 'FW', 'VERB', 'NOUN', 'SYM', 'MD', 'WRB', 'IN']:\n",
    "    qd.calc_match_capital2(test_df, q1, q2, diz=dizionario_max, tipo=i)\n",
    "    \n",
    "for t in ['VERB', 'NOUN', 'JJ', 'WRB']:\n",
    "    train_df['seq_sim_' + t] = train_df.apply(\n",
    "        axis=1, func=lambda x:qd. get_sequenceones_similarity(x[q1], x[q2], [t]))\n",
    "train_df['seq_sim_tot'] = train_df.apply(axis=1, func = lambda x: qd.get_sequenceones_similarity(x[q1],x[q2]))\n",
    "\n",
    "for t in ['VERB', 'NOUN', 'JJ', 'WRB']:\n",
    "    test_df['seq_sim_' + t] = test_df.apply(\n",
    "        axis=1, func=lambda x: qd.get_sequenceones_similarity(x[q1], x[q2], [t]))\n",
    "test_df['seq_sim_tot'] = test_df.apply(axis=1, func = lambda x: qd.get_sequenceones_similarity(x[q1],x[q2]))\n",
    "\n",
    "tempvar = train_df.apply(\n",
    "    axis=1, func=lambda x: qd.getback_function(qd.get_sequenceones_similarity2(x[q1], x[q2])))\n",
    "tempvar.columns = ['seq_sim1', 'seq_sim2']\n",
    "train_df = pd.concat([train_df, tempvar], axis=1)\n",
    "\n",
    "tempvar = test_df.apply(\n",
    "    axis=1, func=lambda x: qd.getback_function(qd.get_sequenceones_similarity2(x[q1], x[q2])))\n",
    "tempvar.columns = ['seq_sim1', 'seq_sim2']\n",
    "test_df = pd.concat([test_df, tempvar], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create \"external\" features\n",
    "\n",
    "- maths\n",
    "- SPOILER alert\n",
    "- unknown words shared\n",
    "- states shared\n",
    "- citizen shared\n",
    "- tvseries shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qd.get_diff_spoiler_math(train_df, q1, q2)\n",
    "qd.get_diff_spoiler_math(test_df, q1, q2)\n",
    "\n",
    "dizionario = qd.load_obj('tag_counter')\n",
    "dizionario['ciccia'] = Counter()\n",
    "\n",
    "serie = pd.read_csv('.\\\\files\\\\tvseries.txt')\n",
    "serie = list(serie['name'].values)\n",
    "states = pd.read_csv('.\\\\files\\\\states.txt')\n",
    "states = list(states['name'].values)\n",
    "citizen = pd.read_csv('.\\\\files\\\\citizen.txt')\n",
    "citizen = list(citizen['name'].values)\n",
    "serie = [n.lower() for n in serie]\n",
    "states = [n.lower() for n in states]\n",
    "citizen = [n.lower() for n in citizen]\n",
    "\n",
    "english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "\n",
    "tempvar = train_df.apply(\n",
    "    axis=1,\n",
    "    func=\n",
    "    lambda x: qd.getback_function(qd.get_unknown_variables(x[q1], x[q2], english_vocab)))\n",
    "tempvar.columns = ['unk1', 'unk2', 'unk3']\n",
    "train_df = pd.concat([train_df, tempvar], axis=1)\n",
    "\n",
    "tempvar = train_df.apply(\n",
    "    axis=1,\n",
    "    func=\n",
    "    lambda x: qd.getback_function(qd.get_variables_from_lists(x[q1], x[q2], serie)))\n",
    "tempvar.columns = ['serie1', 'serie2', 'serie3']\n",
    "train_df = pd.concat([train_df, tempvar], axis=1)\n",
    "\n",
    "tempvar = train_df.apply(\n",
    "    axis=1,\n",
    "    func=\n",
    "    lambda x: qd.getback_function(qd.get_variables_from_lists(x[q1], x[q2], states)))\n",
    "tempvar.columns = ['states1', 'states2', 'states3']\n",
    "train_df = pd.concat([train_df, tempvar], axis=1)\n",
    "\n",
    "tempvar = train_df.apply(\n",
    "    axis=1,\n",
    "    func=\n",
    "    lambda x: qd.getback_function(qd.get_variables_from_lists(x[q1], x[q2], citizen)))\n",
    "tempvar.columns = ['citizen1', 'citizen2', 'citizen3']\n",
    "train_df = pd.concat([train_df, tempvar], axis=1)\n",
    "\n",
    "tempvar = test_df.apply(\n",
    "    axis=1,\n",
    "    func=\n",
    "    lambda x: qd.getback_function(qd.get_unknown_variables(x[q1], x[q2])))\n",
    "tempvar.columns = ['unk1', 'unk2', 'unk3']\n",
    "test_df = pd.concat([test_df, tempvar], axis=1)\n",
    "\n",
    "tempvar = test_df.apply(\n",
    "    axis=1,\n",
    "    func=\n",
    "    lambda x: qd.getback_function(qd.get_variables_from_lists(x[q1], x[q2], serie)))\n",
    "tempvar.columns = ['serie1', 'serie2', 'serie3']\n",
    "test_df = pd.concat([test_df, tempvar], axis=1)\n",
    "\n",
    "tempvar = test_df.apply(\n",
    "    axis=1,\n",
    "    func=\n",
    "    lambda x: qd.getback_function(qd.get_variables_from_lists(x[q1], x[q2], states)))\n",
    "tempvar.columns = ['states1', 'states2', 'states3']\n",
    "test_df = pd.concat([test_df, tempvar], axis=1)\n",
    "\n",
    "tempvar = test_df.apply(\n",
    "    axis=1,\n",
    "    func=\n",
    "    lambda x: qd.getback_function(qd.get_variables_from_lists(x[q1], x[q2], citizen)))\n",
    "tempvar.columns = ['citizen1', 'citizen2', 'citizen3']\n",
    "test_df = pd.concat([test_df, tempvar], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create bit features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc_time = ['as', 'of', 'for', 'up', 'down', 'out', 'on', 'off', 'over', 'under', 'again', 'so',\n",
    "'too', 'very', 'few', 'more', 'most']\n",
    "\n",
    "for i in loc_time:\n",
    "    train_df[i+'_or'] = train_df.apply(axis=1, func=lambda x: qd.get_bit_single_word(x[q1], i) or qd.get_bit_single_word(x[q2], i))\n",
    "    train_df[i+'_and'] = train_df.apply(axis=1, func=lambda x: qd.get_bit_single_word(x[q1], i) and qd.get_bit_single_word(x[q2], i))\n",
    "\n",
    "for i in loc_time:\n",
    "    test_df[i+'_or'] = test_df.apply(axis=1, func=lambda x: qd.get_bit_single_word(x[q1], i) or qd.get_bit_single_word(x[q2], i))\n",
    "    test_df[i+'_and'] = test_df.apply(axis=1, func=lambda x: qd.get_bit_single_word(x[q1], i) and qd.get_bit_single_word(x[q2], i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some features with word2vec\n",
    "\n",
    "- feature extraction using pca on words vector\n",
    "- isomap after pca on difference between phrases\n",
    "- W2V distances between phrases by removing a fraction of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_clear.csv', usecols=(1,6,9,10))\n",
    "test_df = pd.read_csv('test_clear.csv', usecols=(1,6,7))\n",
    "train_df.fillna(\"ciccia\", inplace=True)\n",
    "test_df.fillna(\"ciccia\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1, q2 = 'question1_final', 'question2_final'\n",
    "\n",
    "corpus = qd.build_corpus(train_df, q1, q2)\n",
    "corpus.extend(qd.build_corpus(test_df, q1, q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    corpus,\n",
    "    size=135,\n",
    "    window=10,\n",
    "    min_count=5,\n",
    "    workers=8,\n",
    "    sg=1,\n",
    "    hs=1,\n",
    "    negative=10,\n",
    "    iter=10,\n",
    "    sorted_vocab=-1)\n",
    "\n",
    "model_50 = word2vec.Word2Vec(\n",
    "    corpus,\n",
    "    size=50,\n",
    "    window=10,\n",
    "    min_count=5,\n",
    "    workers=8,\n",
    "    sg=1,\n",
    "    hs=1,\n",
    "    negative=10,\n",
    "    iter=10,\n",
    "    sorted_vocab=-1)\n",
    "\n",
    "model_50.save('model_best_50.bin')\n",
    "model_50.wv.save_word2vec_format('model_best_format_50.bin')\n",
    "\n",
    "model.save('model_best.bin')\n",
    "model.wv.save_word2vec_format('model_best_format.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('.\\\\train_clear.csv', encoding='latin1')\n",
    "\n",
    "q1 = 'question1_final'\n",
    "q2 = 'question2_final'\n",
    "\n",
    "train_df.fillna('ciccia', inplace=True)\n",
    "\n",
    "all_unique_quests = set(list(set(train_df[q1])) + list(set(train_df[q2])))\n",
    "all_words = qd.flatmap(qd.get_words, all_unique_quests)\n",
    "cnt_words = Counter(all_words)\n",
    "\n",
    "cnt_most = cnt_words.most_common(200)\n",
    "cnt_most = [cnt_most[i][0] for i in range(0, 200)]\n",
    "\n",
    "model = gensim.models.KeyedVectors.load('./model_best_50.bin')\n",
    "\n",
    "#train\n",
    "all_train = train_df[['id', q1, q2]].values\n",
    "b = list(map(qd.clear_phrase, all_train))\n",
    "\n",
    "results = []\n",
    "step = 5000\n",
    "\n",
    "for i in range(0, len(b), step):  #len(b)\n",
    "    x = time.clock()\n",
    "    results.extend(list(map(qd.get_phrase_distances2, b[i:i + step])))\n",
    "    y = time.clock() - x\n",
    "    print(str(i) + '/404290 e ci ho impiegato ' + str(y / 60) + ' minuti')\n",
    "\n",
    "myres = np.array(results)\n",
    "temp = train_df.apply(axis=1, func=lambda x: qd.getback_function(myres[x['id']]))\n",
    "temp.columns = ['dist_' + str(i) for i in range(0, 10)]\n",
    "train_df = pd.concat([train_df, temp], axis=1)\n",
    "\n",
    "train_df.replace(np.inf, np.nan, inplace=True)\n",
    "\n",
    "ftrs = list(\n",
    "    set(train_df.columns) - set([\n",
    "        'Unnamed: 0', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n",
    "        'question1_clear_1', 'question2_clear_1', 'question1_final',\n",
    "        'question2_final'\n",
    "    ]))\n",
    "\n",
    "train_df[ftrs].to_csv('train_dist_vars.csv')\n",
    "\n",
    "for n in temp.columns:\n",
    "    print(n)\n",
    "    qd.plot_variable(train_df[np.isfinite(train_df['dist_0'])], n)\n",
    "\n",
    "# test\n",
    "all_test = test_df[['test_id', q1, q2]].values\n",
    "b = list(map(qd.clear_phrase, all_test))\n",
    "\n",
    "results = []\n",
    "step = 5000\n",
    "\n",
    "for i in range(0, len(b), step):  #len(b)\n",
    "    x = time.clock()\n",
    "    results.extend(list(map(qd.get_phrase_distances2, b[i:i + step])))\n",
    "    y = time.clock() - x\n",
    "    print(str(i) + '/2345796 e ci ho impiegato ' + str(y / 60) + ' minuti')\n",
    "\n",
    "myres = np.array(results)\n",
    "temp = test_df.apply(axis=1, func=lambda x: qd.getback_function(myres[x['id']]))\n",
    "temp.columns = ['dist_' + str(i) for i in range(0, 10)]\n",
    "test_df = pd.concat([test_df, temp], axis=1)\n",
    "test_df.replace(np.inf, np.nan, inplace=True)\n",
    "\n",
    "ftrs = list(\n",
    "    set(test_df.columns) - set([\n",
    "        'Unnamed: 0', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n",
    "        'question1_clear_1', 'question2_clear_1', 'question1_final',\n",
    "        'question2_final'\n",
    "    ]))\n",
    "\n",
    "test_df[ftrs].to_csv('test_dist_vars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempvar = train_df.apply(\n",
    "    axis=1, func=lambda x: qd.getback_function(qd.pca_vars(x[q1], x[q2])))\n",
    "tempvar.columns = ['diff_eigenv_pca', 'cos_pca', 'diff_ratio_ecc_pca']\n",
    "train_df = pd.concat([train_df, tempvar], axis=1)\n",
    "train_df.fillna(0, inplace=True)\n",
    "\n",
    "tempvar = test_df.apply(\n",
    "    axis=1, func=lambda x: qd.getback_function(qd.pca_vars(x[q1], x[q2])))\n",
    "tempvar.columns = ['diff_eigenv_pca', 'cos_pca', 'diff_ratio_ecc_pca']\n",
    "test_df = pd.concat([test_df, tempvar], axis=1)\n",
    "test_df.fillna(0, inplace=True)\n",
    "\n",
    "tempvar = train_df.apply(\n",
    "    axis=1, func=lambda x: qd.getback_function(qd.get_W2V_variables(x[q1], x[q2], model)))\n",
    "tempvar.columns = ['norm_mean_wv', 'norm_sum_wv', 'cos_mean_wv', 'cos_sum_wv']\n",
    "train_df = pd.concat([train_df, tempvar], axis=1)\n",
    "train_df.replace(np.inf, np.nan,inplace=True)\n",
    "train_df.fillna(0, inplace=True)\n",
    "\n",
    "tempvar = test_df.apply(\n",
    "    axis=1, func=lambda x: qd.getback_function(qd.get_W2V_variables(x[q1], x[q2], model)))\n",
    "tempvar.columns = ['norm_mean_wv', 'norm_sum_wv', 'cos_mean_wv', 'cos_sum_wv']\n",
    "test_df = pd.concat([test_df, tempvar], axis=1)\n",
    "test_df.replace(np.inf, np.nan,inplace=True)\n",
    "test_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = train.apply(axis=1,func=lambda x: qd.getback_function([qd.get_W2V_sum_sentence(x.question1_final,model)]))\n",
    "v2 = train.apply(axis=1,func=lambda x: qd.getback_function([qd.get_W2V_sum_sentence(x.question2_final,model)]))\n",
    "\n",
    "v3 = test.apply(axis=1,func=lambda x: qd.getback_function([qd.get_W2V_sum_sentence(x.question1_final,model)]))\n",
    "v4 = test.apply(axis=1,func=lambda x: qd.getback_function([qd.get_W2V_sum_sentence(x.question2_final,model)]))\n",
    "\n",
    "name = ['diff_' + str(i) for i in range(0, 50)]\n",
    "\n",
    "train_diff = pd.DataFrame(v1 - v2)\n",
    "train_diff.columns = name\n",
    "train = pd.concat([train, train_diff], axis=1)\n",
    "\n",
    "test_diff = pd.DataFrame(np.abs(v3 - v4))\n",
    "test_diff.columns = name\n",
    "test = pd.concat([test, test_diff], axis=1)\n",
    "\n",
    "train = np.abs(train)\n",
    "test = np.abs(test)\n",
    "\n",
    "traintestpca = pd.concat([train, test], axis=0).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "pca_diff = pca.fit_transform(traintestpca)\n",
    "\n",
    "pca1_train = pca_diff[:404290, 1]\n",
    "pca2_train = pca_diff[:404290, 2]\n",
    "pca3_train = pca_diff[:404290, 3]\n",
    "pca1_test = pca_diff[404290:, 1]\n",
    "pca2_test = pca_diff[404290:, 2]\n",
    "pca3_test = pca_diff[404290:, 3]\n",
    "\n",
    "train_df['pca1'] = pca1_train\n",
    "train_df['pca2'] = pca2_train\n",
    "train_df['pca3'] = pca3_train\n",
    "\n",
    "X_iso_fit = Isomap(\n",
    "    n_neighbors=30, n_components=3).fit(traintestpca.sample(n=1000))\n",
    "\n",
    "step = 50000\n",
    "iso_all = []\n",
    "for i in range(0, 404290, step):\n",
    "    iso_all.extend(\n",
    "        X_iso_fit.transform(\n",
    "            traintestpca[:404290].iloc[0 + i:i + step]))  # 2345796:\n",
    "    print(i)\n",
    "\n",
    "name = 'iso_map_pca'\n",
    "for i in range(0, 3):\n",
    "    j = name + '_' + str(i)\n",
    "    train_df[j] = np.array(iso_all)[:404290, i]\n",
    "\n",
    "qd.plot_variable(train_df[(train_df['pca1'] > -4) & (train_df['pca1'] < 4)],\n",
    "                'pca1')\n",
    "qd.plot_variable(train_df[(train_df['pca2'] > -4) & (train_df['pca2'] < 4)],\n",
    "                'pca2')\n",
    "qd.plot_variable(train_df[(train_df['pca3'] > -4) & (train_df['pca3'] < 4)],\n",
    "                'pca3')\n",
    "qd.plot_variable(train_df[(train_df['iso_map_pca_0'] > -10) &\n",
    "                         (train_df['iso_map_pca_0'] < 10)], 'iso_map_pca_0')\n",
    "qd.plot_variable(train_df[(train_df['iso_map_pca_1'] > -5) &\n",
    "                         (train_df['iso_map_pca_1'] < 5)], 'iso_map_pca_1')\n",
    "qd.plot_variable(train_df[(train_df['iso_map_pca_2'] > -5) &\n",
    "                         (train_df['iso_map_pca_2'] < 5)], 'iso_map_pca_2')\n",
    "\n",
    "test['pca1'] = pca1_test\n",
    "test['pca2'] = pca2_test\n",
    "test['pca3'] = pca3_test\n",
    "\n",
    "traintestpca = traintestpca.iloc[404290:]\n",
    "\n",
    "step = 100000\n",
    "iso_all_test = []\n",
    "\n",
    "for i in range(0, 2345796, step):\n",
    "    iso_all_test.extend(\n",
    "        X_iso_fit.transform(traintestpca.iloc[0 + i:i + step]))  # 2345796:\n",
    "    print(i)\n",
    "\n",
    "name = 'iso_map_pca'\n",
    "for i in range(0, 3):\n",
    "    j = name + '_' + str(i)\n",
    "    test[j] = np.array(iso_all_test)[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1500\n",
    "e_start = 0.3\n",
    "x = np.linspace(0,n,n)\n",
    "eta_adaptive = e_start*(1- (x/(5+x)))\n",
    "eta_adaptive[eta_adaptive<0.05] = 0.05\n",
    "\n",
    "other_par = {\n",
    "    'num_boost_round':n\n",
    "    , 'early_stopping_rounds':50\n",
    "    , 'verbose_eval':20\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'objective':'binary:logistic'\n",
    "    , 'silent': 0\n",
    "    , 'nthread':10\n",
    "    , 'eta':0.05\n",
    "    , 'eval_metric': 'logloss'\n",
    "    , 'maximize':True\n",
    "    , 'max_depth':15\n",
    "    , 'min_child_weight': 15\n",
    "    , 'colsample_bytree': 0.75\n",
    "    , 'subsample': 0.5\n",
    "    , 'gamma': 70\n",
    "    , 'alpha': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventuali = [\n",
    "    'question1_clear_1', 'question2_clear_1', 'question1_clear_1_clear_2',\n",
    "    'question1_clear_1_clear_2', 'question2_clear_1_clear_2', 'question1_final', 'question2_final'\n",
    "]\n",
    "features = list(\n",
    "    set(df.columns) -\n",
    "    set(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate'] +\n",
    "        eventuali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = df[features+['is_duplicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in fields dist_7, dist_5, dist_0, cos_pca, dist_2, dist_9, dist_6, dist_8, dist_4, dist_3, dist_1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-57b4599e148e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_xgb, roc_auc_test, roc_auc_train, var_imp = train_xgboost(\n\u001b[0;32m----> 2\u001b[0;31m     x_train, features, 'is_duplicate', params, other_par)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-24f53fabd3e0>\u001b[0m in \u001b[0;36mtrain_xgboost\u001b[0;34m(df, features, target, param, other_par)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mw_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mw_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mxg_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mxg_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    253\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[1;32m    254\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                                                                 feature_types)\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_pandas_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[0;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    179\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[1;32m    180\u001b[0m Did not expect the data types in fields \"\"\"\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in fields dist_7, dist_5, dist_0, cos_pca, dist_2, dist_9, dist_6, dist_8, dist_4, dist_3, dist_1"
     ]
    }
   ],
   "source": [
    "model_xgb, roc_auc_test, roc_auc_train, var_imp = train_xgboost_w(\n",
    "    x_train, features, 'is_duplicate', params, other_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_par = {\n",
    "    'num_boost_round':1500\n",
    "    , 'early_stopping_rounds':50\n",
    "    , 'verbose_eval':False\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'objective':'binary:logistic'\n",
    "    , 'silent': 0\n",
    "    , 'nthread':10\n",
    "    , 'eta':0.02\n",
    "    , 'eval_metric': 'logloss'\n",
    "    , 'maximize':True\n",
    "}\n",
    "\n",
    "myranges = {\n",
    "    'min_child_weight': (1, 250),\n",
    "    'colsample_bytree': (0.5, 1),\n",
    "    'max_depth': (14, 25),\n",
    "    'subsample': (0.5, 1),\n",
    "    'gamma': (0, 300),\n",
    "    'alpha': (0, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target = 'is_duplicate'\n",
    "df = df.sample(frac=1)\n",
    "X_train, X_test, y_train, y_test = qd.train_test_split(\n",
    "    df[features], df[target], test_size=0.33, random_state=786)\n",
    "r = df[target].value_counts()[0]/df[target].value_counts()[1]\n",
    "r = 1./0.165\n",
    "w_train = y_train*r\n",
    "w_train[y_train == 0] = 1\n",
    "w_test = y_test*r\n",
    "w_test[y_test == 0] = 1  \n",
    "xg_train = xgb.DMatrix(X_train, label=y_train, weight=w_train)\n",
    "xg_test = xgb.DMatrix(X_test, label=y_test, weight=w_test)\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 22m56s | \u001b[35m  -0.34066\u001b[0m | \u001b[32m  30.2880\u001b[0m | \u001b[32m            0.9175\u001b[0m | \u001b[32m 110.4182\u001b[0m | \u001b[32m     7.1815\u001b[0m | \u001b[32m           12.9789\u001b[0m | \u001b[32m     0.8514\u001b[0m | \n",
      "    2 | 36m23s |   -0.34373 |   80.8833 |             0.5971 |   72.5274 |     10.3191 |            15.4048 |      0.5227 | \n",
      "    3 | 23m45s |   -0.34761 |   75.2651 |             0.6445 |  143.2929 |      8.4753 |            23.7030 |      0.8974 | \n",
      "    4 | 36m27s | \u001b[35m  -0.33832\u001b[0m | \u001b[32m  62.8072\u001b[0m | \u001b[32m            0.8326\u001b[0m | \u001b[32m  90.3208\u001b[0m | \u001b[32m    11.3920\u001b[0m | \u001b[32m           66.0692\u001b[0m | \u001b[32m     0.9088\u001b[0m | \n",
      "    5 | 20m05s |   -0.36143 |   84.4648 |             0.7767 |  276.1428 |     11.7368 |            16.7507 |      0.7673 | \n",
      "    6 | 38m00s | \u001b[35m  -0.33072\u001b[0m | \u001b[32m  64.3275\u001b[0m | \u001b[32m            0.7923\u001b[0m | \u001b[32m  49.6461\u001b[0m | \u001b[32m    10.6945\u001b[0m | \u001b[32m           27.9142\u001b[0m | \u001b[32m     0.8020\u001b[0m | \n",
      "    7 | 16m15s |   -0.35682 |    3.3102 |             0.9109 |  263.5040 |      6.2454 |            25.4674 |      0.7714 | \n",
      "    8 | 18m33s |   -0.35473 |   23.3874 |             0.9741 |  265.8568 |      9.8374 |           205.7052 |      0.9331 | \n",
      "    9 | 30m28s |   -0.35910 |   51.4916 |             0.8945 |  267.2346 |     14.5804 |           104.0554 |      0.7299 | \n",
      "   10 | 33m37s |   -0.34027 |   51.7779 |             0.6666 |   98.1530 |      9.7967 |           113.0167 |      0.8016 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  2.15478802e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "   11 | 26m17s | \u001b[35m  -0.31815\u001b[0m | \u001b[32m   0.6696\u001b[0m | \u001b[32m            0.9308\u001b[0m | \u001b[32m   1.6009\u001b[0m | \u001b[32m     8.2270\u001b[0m | \u001b[32m          248.3678\u001b[0m | \u001b[32m     0.7654\u001b[0m | \n",
      "   12 | 25m24s |   -0.32258 |   99.1646 |             0.5584 |    8.2901 |      7.9599 |           249.6885 |      0.9099 | \n",
      "   13 | 15m33s |   -0.32439 |    0.3517 |             0.5659 |    2.8390 |     14.8680 |             4.3856 |      0.5030 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -1.63214935e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 17m50s |   -0.32838 |    8.5788 |             0.9738 |    1.8492 |      5.0337 |           126.4519 |      0.5969 | \n",
      "   15 | 45m41s |   -0.34145 |    3.7402 |             0.8735 |  110.0126 |     14.7778 |           248.5686 |      0.5632 | \n",
      "   16 | 09m47s |   -0.36625 |   99.2722 |             0.7380 |  294.7368 |      5.3590 |           247.3311 |      0.6702 | \n",
      "   17 | 47m23s | \u001b[35m  -0.31171\u001b[0m | \u001b[32m  93.1871\u001b[0m | \u001b[32m            0.7402\u001b[0m | \u001b[32m   0.7411\u001b[0m | \u001b[32m    14.7669\u001b[0m | \u001b[32m          108.5365\u001b[0m | \u001b[32m     0.9173\u001b[0m | \n",
      "   18 | 21m18s |   -0.32653 |   97.2299 |             0.6708 |    1.5833 |      5.5776 |            55.2902 |      0.6512 | \n",
      "   19 | 43m10s |   -0.31552 |   60.8743 |             0.7919 |    0.3971 |     14.4955 |           195.3390 |      0.5771 | \n",
      "   20 | 45m48s |   -0.31318 |   99.8837 |             0.6491 |    2.8798 |     14.9283 |           153.3007 |      0.9968 | \n",
      "   21 | 50m05s | \u001b[35m  -0.30856\u001b[0m | \u001b[32m  45.3265\u001b[0m | \u001b[32m            0.9738\u001b[0m | \u001b[32m   2.1108\u001b[0m | \u001b[32m    14.8426\u001b[0m | \u001b[32m           71.1777\u001b[0m | \u001b[32m     0.8064\u001b[0m | \n",
      "   22 | 43m59s |   -0.31392 |   46.2357 |             0.9832 |    0.9356 |     13.8469 |           247.7224 |      0.6550 | \n",
      "   23 | 37m43s |   -0.30921 |    2.4781 |             0.5259 |    1.2705 |     14.4362 |            63.8092 |      0.9743 | \n",
      "   24 | 51m39s |   -0.31388 |    1.0511 |             0.5571 |   32.2557 |     14.7076 |            66.8502 |      0.6027 | \n",
      "   25 | 47m57s |   -0.30939 |    3.8198 |             0.6341 |    0.2758 |     14.9542 |           214.7929 |      0.7928 | \n",
      "   26 | 43m22s | \u001b[35m  -0.30840\u001b[0m | \u001b[32m  11.2009\u001b[0m | \u001b[32m            0.8923\u001b[0m | \u001b[32m   1.4835\u001b[0m | \u001b[32m    14.9467\u001b[0m | \u001b[32m           89.1675\u001b[0m | \u001b[32m     0.7433\u001b[0m | \n",
      "   27 | 51m36s |   -0.31205 |   90.5570 |             0.8576 |    2.5823 |     14.8975 |             3.2009 |      0.6020 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -3.06363068e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 26m18s |   -0.35990 |    0.2062 |             0.7408 |  299.6955 |     14.6219 |           246.3253 |      0.6300 | \n",
      "   29 | 28m58s |   -0.35542 |   99.0846 |             0.6269 |  146.7525 |     14.8328 |           247.1198 |      0.5897 | \n",
      "   30 | 49m22s |   -0.30913 |   53.3951 |             0.8917 |    0.2078 |     14.9422 |            32.6846 |      0.8744 | \n",
      "   31 | 51m24s |   -0.34326 |    0.1021 |             0.6005 |  156.9008 |     14.7436 |            95.1311 |      0.7324 | \n",
      "   32 | 43m48s |   -0.30943 |   54.8727 |             0.6310 |    0.8879 |     14.4522 |           114.8393 |      0.9980 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -3.99722549e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 42m55s |   -0.31887 |   93.1281 |             0.5413 |    0.4951 |     14.9974 |           245.7469 |      0.6142 | \n",
      "   34 | 46m52s |   -0.31877 |   13.1527 |             0.9981 |   38.0240 |     14.7632 |           214.8538 |      0.8860 | \n",
      "   35 | 45m24s |   -0.30844 |    5.4838 |             0.7620 |    3.3574 |     14.9620 |           175.8215 |      0.9743 | \n",
      "   36 | 46m26s |   -0.30919 |   47.9023 |             0.7800 |    2.8984 |     14.9278 |           151.2222 |      0.9774 | \n",
      "   37 | 45m57s |   -0.32931 |   59.7161 |             0.6971 |   33.0900 |     14.9995 |           142.7598 |      0.5602 | \n",
      "   38 | 54m39s |   -0.34550 |    2.5252 |             0.7673 |  169.8156 |     14.4513 |             1.1195 |      0.7219 | \n",
      "   39 | 49m58s | \u001b[35m  -0.30771\u001b[0m | \u001b[32m  28.2608\u001b[0m | \u001b[32m            0.5847\u001b[0m | \u001b[32m   6.4338\u001b[0m | \u001b[32m    14.8763\u001b[0m | \u001b[32m           45.7781\u001b[0m | \u001b[32m     0.9069\u001b[0m | \n",
      "   40 | 45m31s |   -0.31155 |   29.8622 |             0.6408 |    1.2015 |     14.3428 |           186.4499 |      0.6210 | \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d07f55483a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mother_par\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_par\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmyranges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyranges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     sgn=-1)\n\u001b[0m",
      "\u001b[0;32m/home/ale/random_program/Quora_double_question/ourfunctions.py\u001b[0m in \u001b[0;36mgo_with_BayesianOptimization\u001b[0;34m(xg_train, xg_test, watchlist, params, other_par, num_iter, init_points, acq, kappa, myranges, sgn)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     xgbBO.maximize(\n\u001b[1;32m   1154\u001b[0m         \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m         kappa=kappa)  # poi, ei, ucb\n\u001b[0m\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m# Append most recently generated values to X and Y arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Updating the GP.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/random_program/Quora_double_question/ourfunctions.py\u001b[0m in \u001b[0;36mxgb_evaluate\u001b[0;34m(min_child_weight, colsample_bytree, max_depth, subsample, gamma, alpha)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m#                   seed=random_state, callbacks=[xgb.callback.early_stop(25)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         model_temp = xgb.train(\n\u001b[0;32m-> 1124\u001b[0;31m             dtrain=xg_train, evals=watchlist, params=params, **other_par)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;31m# return -cv_result['test-merror-mean'].values[-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msgn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgbBO = qd.go_with_BayesianOptimization(\n",
    "    xg_train,\n",
    "    xg_test,\n",
    "    watchlist,\n",
    "    kappa=4,\n",
    "    init_points=10,\n",
    "    num_iter=150,\n",
    "    params=params,\n",
    "    other_par=other_par,\n",
    "    myranges=myranges,\n",
    "    sgn=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 39m06s | \u001b[35m  -0.35439\u001b[0m | \u001b[32m  40.9091\u001b[0m | \u001b[32m            0.8879\u001b[0m | \u001b[32m 209.7051\u001b[0m | \u001b[32m    14.7205\u001b[0m | \u001b[32m          209.1722\u001b[0m | \u001b[32m     0.7074\u001b[0m | \n",
      "    2 | 47m55s | \u001b[35m  -0.34504\u001b[0m | \u001b[32m  47.2878\u001b[0m | \u001b[32m            0.9610\u001b[0m | \u001b[32m 119.4465\u001b[0m | \u001b[32m    15.3950\u001b[0m | \u001b[32m          135.2350\u001b[0m | \u001b[32m     0.6957\u001b[0m | \n",
      "    3 | 43m39s | \u001b[35m  -0.32722\u001b[0m | \u001b[32m  35.9217\u001b[0m | \u001b[32m            0.6858\u001b[0m | \u001b[32m  34.2860\u001b[0m | \u001b[32m    15.1360\u001b[0m | \u001b[32m          241.8153\u001b[0m | \u001b[32m     0.5349\u001b[0m | \n",
      "    4 | 56m28s |   -0.33521 |   33.1134 |             0.5365 |   89.7676 |     19.0541 |           117.0763 |      0.8600 | \n",
      "    5 | 22m59s |   -0.36261 |   95.6889 |             0.9369 |  267.1396 |     14.0558 |           231.3146 |      0.7032 | \n",
      "    6 | 64m28s |   -0.34798 |   37.6857 |             0.5635 |  155.4990 |     21.6794 |            44.4108 |      0.7215 | \n",
      "    7 | 56m20s |   -0.33450 |   28.3308 |             0.8464 |   89.0903 |     24.0621 |           207.7963 |      0.9485 | \n",
      "    8 | 64m15s |   -0.33547 |   78.2682 |             0.7521 |   56.0049 |     20.7525 |            39.7263 |      0.6990 | \n",
      "    9 | 38m24s |   -0.34970 |   41.5086 |             0.9748 |  186.7007 |     18.6853 |            53.9903 |      0.9491 | \n",
      "   10 | 25m01s |   -0.36135 |   24.0583 |             0.9582 |  260.9471 |     22.4963 |           229.0120 |      0.5641 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "   11 | 17m00s |   -0.32849 |    2.7808 |             0.7340 |    0.6996 |     19.0942 |             4.4397 |      0.5308 | \n",
      "   12 | 52m37s | \u001b[35m  -0.31593\u001b[0m | \u001b[32m  99.8932\u001b[0m | \u001b[32m            0.5787\u001b[0m | \u001b[32m   0.3930\u001b[0m | \u001b[32m    24.0735\u001b[0m | \u001b[32m          177.0115\u001b[0m | \u001b[32m     0.7267\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -3.53294692e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -2.55037043e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -9.15748522e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  2.30744884e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 59m56s | \u001b[35m  -0.30812\u001b[0m | \u001b[32m   5.8836\u001b[0m | \u001b[32m            0.9930\u001b[0m | \u001b[32m   0.0201\u001b[0m | \u001b[32m    22.5715\u001b[0m | \u001b[32m          155.1168\u001b[0m | \u001b[32m     0.7922\u001b[0m | \n",
      "   14 | 66m22s | \u001b[35m  -0.30771\u001b[0m | \u001b[32m   0.7909\u001b[0m | \u001b[32m            0.8192\u001b[0m | \u001b[32m   0.6420\u001b[0m | \u001b[32m    23.2454\u001b[0m | \u001b[32m          221.3153\u001b[0m | \u001b[32m     0.9933\u001b[0m | \n",
      "   15 | 31m55s |   -0.36133 |   98.9739 |             0.5986 |  299.4269 |     20.4427 |             4.4245 |      0.9434 | \n",
      "   16 | 49m34s |   -0.30837 |   10.5616 |             0.6250 |    0.1537 |     24.5326 |            96.2393 |      0.7614 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  2.45236079e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 52m08s |   -0.31441 |   96.2783 |             0.6723 |    0.5884 |     23.8512 |           243.4796 |      0.8714 | \n",
      "   18 | 57m42s |   -0.31008 |   37.7618 |             0.6447 |    0.3201 |     24.3899 |           186.3127 |      0.7086 | \n",
      "   19 | 55m35s |   -0.31204 |   14.7288 |             0.6732 |    0.8867 |     24.3769 |           248.4960 |      0.5310 | \n",
      "   20 | 66m17s |   -0.30964 |    3.9783 |             0.5737 |    0.4043 |     24.5980 |           182.1146 |      0.5926 | \n",
      "   21 | 62m20s |   -0.30946 |   73.9897 |             0.5608 |    0.3025 |     24.4239 |            99.7665 |      0.9610 | \n",
      "   22 | 73m01s |   -0.31141 |   99.8335 |             0.5765 |    2.1759 |     23.2525 |             7.0532 |      0.7080 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00019033]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -4.33475152e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 | 46m33s |   -0.31138 |   98.9621 |             0.5712 |    1.1259 |     14.0705 |            58.3244 |      0.9225 | \n",
      "   24 | 49m06s |   -0.30967 |   40.5088 |             0.6906 |    1.3559 |     15.4265 |           117.2166 |      0.7209 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -1.26219243e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 63m13s |   -0.31011 |   44.7346 |             0.8490 |    0.2750 |     24.7136 |            68.4267 |      0.6126 | \n",
      "   26 | 62m41s |   -0.30843 |   41.3380 |             0.9789 |    1.0484 |     24.6976 |           132.1144 |      0.8146 | \n",
      "   27 | 55m50s |   -0.30910 |    2.6147 |             0.8540 |    1.0764 |     24.7126 |           135.0514 |      0.5874 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00011016]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 44m34s |   -0.35675 |    0.2699 |             0.7420 |  292.0935 |     20.2122 |             2.6155 |      0.7605 | \n",
      "   29 | 66m37s |   -0.31221 |   98.0954 |             0.5113 |    0.5087 |     23.9113 |            42.6436 |      0.7495 | \n",
      "   30 | 45m39s |   -0.30904 |    9.3252 |             0.9185 |    0.3846 |     14.8397 |           221.6919 |      0.9531 | \n",
      "   31 | 50m56s |   -0.30814 |   27.2849 |             0.5164 |    0.6085 |     15.5688 |           153.1154 |      0.8479 | \n",
      "   32 | 42m04s |   -0.31012 |    2.0498 |             0.9014 |    0.8738 |     14.3822 |           247.4683 |      0.9685 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -7.12932861e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 62m07s |   -0.30884 |   58.5612 |             0.8830 |    0.0770 |     24.7369 |           147.9597 |      0.9621 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00017757]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 44m26s |   -0.30812 |    0.3357 |             0.6579 |    0.6736 |     14.0217 |            94.7632 |      0.8891 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0002341]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 42m35s |   -0.31819 |   95.6468 |             0.8181 |    1.3811 |     14.1107 |           118.6550 |      0.5341 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -7.89216033e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 52m02s |   -0.31063 |   69.8374 |             0.8851 |    0.1619 |     15.3553 |            28.0674 |      0.6940 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  1.86705402e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 44m14s |   -0.30869 |   41.5699 |             0.7984 |    0.3015 |     14.0881 |            87.4885 |      0.9978 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00073698]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   38 | 55m59s |   -0.30902 |   66.3239 |             0.9282 |    0.0420 |     18.4651 |            72.1133 |      0.9777 | \n",
      "   39 | 46m08s |   -0.31010 |    9.7401 |             0.7009 |    0.3059 |     14.2532 |           112.4993 |      0.5290 | \n",
      "   40 | 39m58s |   -0.30833 |    0.2566 |             0.6293 |    0.0413 |     14.5258 |            68.2951 |      0.7891 | \n",
      "   41 | 63m20s | \u001b[35m  -0.30768\u001b[0m | \u001b[32m  40.1063\u001b[0m | \u001b[32m            0.9711\u001b[0m | \u001b[32m   0.8375\u001b[0m | \u001b[32m    23.8364\u001b[0m | \u001b[32m          155.1179\u001b[0m | \u001b[32m     0.9538\u001b[0m | \n",
      "   42 | 47m20s | \u001b[35m  -0.30742\u001b[0m | \u001b[32m  22.8385\u001b[0m | \u001b[32m            0.6601\u001b[0m | \u001b[32m   0.8411\u001b[0m | \u001b[32m    15.3924\u001b[0m | \u001b[32m           75.9327\u001b[0m | \u001b[32m     0.8937\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ 0.00091882]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 46m34s |   -0.30978 |    0.0240 |             0.7927 |    0.3399 |     14.2585 |           162.0086 |      0.6920 | \n",
      "   44 | 49m40s |   -0.31584 |   71.1312 |             0.8211 |    0.0390 |     24.9970 |           212.3112 |      0.6052 | \n",
      "   45 | 41m55s |   -0.30872 |    2.5027 |             0.9023 |    1.3560 |     23.8367 |            77.8532 |      0.7399 | \n",
      "   46 | 66m36s |   -0.30748 |   26.7218 |             0.6785 |    0.7371 |     24.7548 |           167.1256 |      0.9742 | \n",
      "   47 | 47m35s |   -0.30963 |   94.6468 |             0.6948 |    1.1237 |     14.1094 |            15.2666 |      0.9577 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -2.22679721e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 43m36s |   -0.30770 |    7.6408 |             0.9449 |    0.0396 |     15.0925 |            85.8072 |      0.8853 | \n",
      "   49 | 60m21s | \u001b[35m  -0.30721\u001b[0m | \u001b[32m  22.6943\u001b[0m | \u001b[32m            0.7216\u001b[0m | \u001b[32m   1.1096\u001b[0m | \u001b[32m    24.6520\u001b[0m | \u001b[32m          151.9854\u001b[0m | \u001b[32m     0.9805\u001b[0m | \n",
      "   50 | 41m32s |   -0.30804 |   22.7657 |             0.9886 |    0.6089 |     15.2693 |            62.2829 |      0.9661 | \n",
      "   51 | 43m32s |   -0.30775 |    7.1888 |             0.6709 |   14.0725 |     14.0497 |            78.9252 |      0.9636 | \n",
      "   52 | 73m20s |   -0.31141 |    0.1914 |             0.7702 |   33.2041 |     24.8587 |           131.6590 |      0.9561 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00013552]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53 | 72m23s |   -0.31119 |    0.0571 |             0.8954 |   34.5318 |     23.6798 |            88.0164 |      0.9706 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00027982]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   54 | 66m07s |   -0.30902 |   26.6233 |             0.5966 |   14.4848 |     24.2913 |           148.9095 |      0.9995 | \n",
      "   55 | 50m42s |   -0.30793 |    1.6068 |             0.6985 |   18.3976 |     15.5233 |           101.1254 |      0.8895 | \n",
      "   56 | 64m20s |   -0.30845 |   53.1303 |             0.9457 |    0.3448 |     24.9161 |            99.8781 |      0.8858 | \n",
      "   57 | 70m16s |   -0.30800 |   25.6143 |             0.7789 |   14.5492 |     24.1640 |            91.4880 |      0.9838 | \n",
      "   58 | 70m19s |   -0.30951 |   23.7674 |             0.9166 |   18.9148 |     24.8147 |           113.0227 |      0.9846 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -3.62047685e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59 | 54m07s |   -0.30795 |   26.4134 |             0.8794 |    0.0068 |     23.9872 |            97.8655 |      0.9193 | \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d07f55483a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mother_par\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_par\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmyranges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyranges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     sgn=-1)\n\u001b[0m",
      "\u001b[0;32m/home/ale/random_program/Quora_double_question/ourfunctions.py\u001b[0m in \u001b[0;36mgo_with_BayesianOptimization\u001b[0;34m(xg_train, xg_test, watchlist, params, other_par, num_iter, init_points, acq, kappa, myranges, sgn)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     xgbBO.maximize(\n\u001b[1;32m   1154\u001b[0m         \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m         kappa=kappa)  # poi, ei, ucb\n\u001b[0m\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m# Append most recently generated values to X and Y arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Updating the GP.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/random_program/Quora_double_question/ourfunctions.py\u001b[0m in \u001b[0;36mxgb_evaluate\u001b[0;34m(min_child_weight, colsample_bytree, max_depth, subsample, gamma, alpha)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m#                   seed=random_state, callbacks=[xgb.callback.early_stop(25)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         model_temp = xgb.train(\n\u001b[0;32m-> 1124\u001b[0;31m             dtrain=xg_train, evals=watchlist, params=params, **other_par)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;31m# return -cv_result['test-merror-mean'].values[-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msgn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgbBO = qd.go_with_BayesianOptimization(\n",
    "    xg_train,\n",
    "    xg_test,\n",
    "    watchlist,\n",
    "    kappa=4,\n",
    "    init_points=10,\n",
    "    num_iter=150,\n",
    "    params=params,\n",
    "    other_par=other_par,\n",
    "    myranges=myranges,\n",
    "    sgn=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.682476\ttest-logloss:0.682646\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-logloss:0.533695\ttest-logloss:0.536705\n",
      "[40]\ttrain-logloss:0.453194\ttest-logloss:0.458528\n",
      "[60]\ttrain-logloss:0.406491\ttest-logloss:0.413945\n",
      "[80]\ttrain-logloss:0.377739\ttest-logloss:0.38719\n",
      "[100]\ttrain-logloss:0.358584\ttest-logloss:0.370053\n",
      "[120]\ttrain-logloss:0.345586\ttest-logloss:0.358891\n",
      "[140]\ttrain-logloss:0.33546\ttest-logloss:0.350698\n",
      "[160]\ttrain-logloss:0.327844\ttest-logloss:0.344904\n",
      "[180]\ttrain-logloss:0.321875\ttest-logloss:0.340596\n",
      "[200]\ttrain-logloss:0.317022\ttest-logloss:0.337165\n",
      "[220]\ttrain-logloss:0.312479\ttest-logloss:0.334028\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0aa7c38bea7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mretrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_xgboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_duplicate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_par\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-24f53fabd3e0>\u001b[0m in \u001b[0;36mtrain_xgboost\u001b[0;34m(df, features, target, param, other_par)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mxg_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mother_par\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ale/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## RETRAIN THE BEST MODEL HERE AFTER BAYEASIAN OPTIMIZATION\n",
    "n = 1500\n",
    "\n",
    "other_par = {\n",
    "    'num_boost_round':n\n",
    "    , 'early_stopping_rounds':50\n",
    "    , 'verbose_eval':20\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'objective':'binary:logistic'\n",
    "    , 'silent': 0\n",
    "    , 'nthread':10\n",
    "    , 'eta':0.02\n",
    "    , 'eval_metric': 'logloss'\n",
    "    , 'maximize':True\n",
    "    , 'max_depth':15\n",
    "    , 'min_child_weight': 45.7781\n",
    "    , 'colsample_bytree': 0.5847\n",
    "    , 'subsample': 0.9069\n",
    "    , 'gamma': 6.4338 \n",
    "    , 'alpha': 28.2608\n",
    "}\n",
    "\n",
    "\n",
    "retrain = train_xgboost(df, features, 'is_duplicate', params, other_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_duplicate', 'id']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if test has the same variables of train\n",
    "list(set(train_df.columns) - set(test_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv created\n"
     ]
    }
   ],
   "source": [
    "qd.create_submission_xgboost(test_df, features, retrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['predict_proba'] = retrain.predict(xgboost.DMatrix(train_df[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_final</th>\n",
       "      <th>question2_final</th>\n",
       "      <th>diff_and_star_in</th>\n",
       "      <th>diff_or_dollar</th>\n",
       "      <th>diff_and_end_point</th>\n",
       "      <th>diff_or_under_in</th>\n",
       "      <th>diff_and_hat_in</th>\n",
       "      <th>diff_and_tilde_in</th>\n",
       "      <th>...</th>\n",
       "      <th>1_word_match</th>\n",
       "      <th>2_word_match</th>\n",
       "      <th>3_word_match</th>\n",
       "      <th>1_2_word_match</th>\n",
       "      <th>1_3_word_match</th>\n",
       "      <th>2_3_word_match</th>\n",
       "      <th>1_2_3_word_match</th>\n",
       "      <th>sum_first_log</th>\n",
       "      <th>word_share_tfidf</th>\n",
       "      <th>predict_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>How be new Harry Potter book Harry Potter curs...</td>\n",
       "      <td>how bad be new book J K Rowling</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-13.126410</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>0.005416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>what be good book ever make</td>\n",
       "      <td>what be important book you have ever read</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-13.522170</td>\n",
       "      <td>0.438651</td>\n",
       "      <td>0.112567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>what be some well romantic movie English</td>\n",
       "      <td>what be well romantic movie you have ever see</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-13.522170</td>\n",
       "      <td>0.896681</td>\n",
       "      <td>0.131273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>what cause nightmare</td>\n",
       "      <td>what cause nightmare seem real</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-13.522170</td>\n",
       "      <td>0.942560</td>\n",
       "      <td>0.181026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>who be Rohingya Muslims</td>\n",
       "      <td>who be Rohingya people</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-10.672345</td>\n",
       "      <td>0.995288</td>\n",
       "      <td>0.125229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  is_duplicate                                    question1_final  \\\n",
       "62    62             1  How be new Harry Potter book Harry Potter curs...   \n",
       "66    66             1                        what be good book ever make   \n",
       "92    92             1           what be some well romantic movie English   \n",
       "93    93             1                               what cause nightmare   \n",
       "135  135             1                            who be Rohingya Muslims   \n",
       "\n",
       "                                   question2_final diff_and_star_in  \\\n",
       "62                 how bad be new book J K Rowling            False   \n",
       "66       what be important book you have ever read            False   \n",
       "92   what be well romantic movie you have ever see            False   \n",
       "93                  what cause nightmare seem real            False   \n",
       "135                         who be Rohingya people            False   \n",
       "\n",
       "    diff_or_dollar diff_and_end_point diff_or_under_in diff_and_hat_in  \\\n",
       "62           False              False            False           False   \n",
       "66           False              False            False           False   \n",
       "92           False              False            False           False   \n",
       "93           False              False            False           False   \n",
       "135          False              False            False           False   \n",
       "\n",
       "    diff_and_tilde_in      ...       1_word_match 2_word_match  3_word_match  \\\n",
       "62              False      ...              False        False         False   \n",
       "66              False      ...               True         True         False   \n",
       "92              False      ...               True         True         False   \n",
       "93              False      ...               True         True          True   \n",
       "135             False      ...               True         True          True   \n",
       "\n",
       "    1_2_word_match  1_3_word_match 2_3_word_match  1_2_3_word_match  \\\n",
       "62           False           False          False             False   \n",
       "66            True           False          False             False   \n",
       "92            True           False          False             False   \n",
       "93            True            True           True              True   \n",
       "135           True            True           True              True   \n",
       "\n",
       "    sum_first_log word_share_tfidf  predict_proba  \n",
       "62     -13.126410         0.008324       0.005416  \n",
       "66     -13.522170         0.438651       0.112567  \n",
       "92     -13.522170         0.896681       0.131273  \n",
       "93     -13.522170         0.942560       0.181026  \n",
       "135    -10.672345         0.995288       0.125229  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df.is_duplicate==1) & (train_df.predict_proba<0.2)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_final</th>\n",
       "      <th>question2_final</th>\n",
       "      <th>diff_and_star_in</th>\n",
       "      <th>diff_or_dollar</th>\n",
       "      <th>diff_and_end_point</th>\n",
       "      <th>diff_or_under_in</th>\n",
       "      <th>diff_and_hat_in</th>\n",
       "      <th>diff_and_tilde_in</th>\n",
       "      <th>...</th>\n",
       "      <th>1_word_match</th>\n",
       "      <th>2_word_match</th>\n",
       "      <th>3_word_match</th>\n",
       "      <th>1_2_word_match</th>\n",
       "      <th>1_3_word_match</th>\n",
       "      <th>2_3_word_match</th>\n",
       "      <th>1_2_3_word_match</th>\n",
       "      <th>sum_first_log</th>\n",
       "      <th>word_share_tfidf</th>\n",
       "      <th>predict_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19249</th>\n",
       "      <td>19249</td>\n",
       "      <td>0</td>\n",
       "      <td>what be like many poor people America</td>\n",
       "      <td>what work be like many poor people America</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.352217e+01</td>\n",
       "      <td>0.983210</td>\n",
       "      <td>0.963356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25157</th>\n",
       "      <td>25157</td>\n",
       "      <td>0</td>\n",
       "      <td>how do you say I miss you my love farsi</td>\n",
       "      <td>Farsi how do you say I miss you</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9.959609e-07</td>\n",
       "      <td>0.999049</td>\n",
       "      <td>0.937159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26052</th>\n",
       "      <td>26052</td>\n",
       "      <td>0</td>\n",
       "      <td>how do I lose 20 kgs year</td>\n",
       "      <td>how can I lose weight quickly</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.312641e+01</td>\n",
       "      <td>0.042834</td>\n",
       "      <td>0.908189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28540</th>\n",
       "      <td>28540</td>\n",
       "      <td>0</td>\n",
       "      <td>how do I invest my money wisely</td>\n",
       "      <td>how can I invest my money wisely</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.312641e+01</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.934331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39986</th>\n",
       "      <td>39986</td>\n",
       "      <td>0</td>\n",
       "      <td>what be difference between freemason Illuminati</td>\n",
       "      <td>what be difference between Freemason Illuminati</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.352217e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  is_duplicate                                  question1_final  \\\n",
       "19249  19249             0            what be like many poor people America   \n",
       "25157  25157             0          how do you say I miss you my love farsi   \n",
       "26052  26052             0                        how do I lose 20 kgs year   \n",
       "28540  28540             0                  how do I invest my money wisely   \n",
       "39986  39986             0  what be difference between freemason Illuminati   \n",
       "\n",
       "                                       question2_final diff_and_star_in  \\\n",
       "19249       what work be like many poor people America            False   \n",
       "25157                  Farsi how do you say I miss you            False   \n",
       "26052                    how can I lose weight quickly            False   \n",
       "28540                 how can I invest my money wisely            False   \n",
       "39986  what be difference between Freemason Illuminati            False   \n",
       "\n",
       "      diff_or_dollar diff_and_end_point diff_or_under_in diff_and_hat_in  \\\n",
       "19249          False              False            False           False   \n",
       "25157          False              False            False           False   \n",
       "26052          False              False            False           False   \n",
       "28540          False              False            False           False   \n",
       "39986          False              False            False           False   \n",
       "\n",
       "      diff_and_tilde_in      ...       1_word_match 2_word_match  \\\n",
       "19249             False      ...               True        False   \n",
       "25157             False      ...              False        False   \n",
       "26052             False      ...               True        False   \n",
       "28540             False      ...               True        False   \n",
       "39986             False      ...               True         True   \n",
       "\n",
       "       3_word_match 1_2_word_match  1_3_word_match 2_3_word_match  \\\n",
       "19249         False          False           False          False   \n",
       "25157         False          False           False          False   \n",
       "26052          True          False            True          False   \n",
       "28540          True          False            True          False   \n",
       "39986          True           True            True           True   \n",
       "\n",
       "       1_2_3_word_match sum_first_log word_share_tfidf  predict_proba  \n",
       "19249             False -1.352217e+01         0.983210       0.963356  \n",
       "25157             False  9.959609e-07         0.999049       0.937159  \n",
       "26052             False -1.312641e+01         0.042834       0.908189  \n",
       "28540             False -1.312641e+01         0.999856       0.934331  \n",
       "39986              True -1.352217e+01         1.000000       0.920126  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df.is_duplicate==0) & (train_df.predict_proba>0.9)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "421px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "884px",
    "left": "0px",
    "right": "1643px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
