{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev3 toc-item\"><a href=\"#Shannon-Entropy-of-the-phrase:-as-expected-it-didn't-work----&gt;-removed\" data-toc-modified-id=\"Shannon-Entropy-of-the-phrase:-as-expected-it-didn't-work---->-removed-001\"><span class=\"toc-item-num\">0.0.1&nbsp;&nbsp;</span>Shannon Entropy of the phrase: as expected it didn't work ---&gt; removed</a></div><div class=\"lev3 toc-item\"><a href=\"#Another-variables-take-from-kaggle-(frequency-of-the-question)-###-ELIMINATED\" data-toc-modified-id=\"Another-variables-take-from-kaggle-(frequency-of-the-question)-###-ELIMINATED-002\"><span class=\"toc-item-num\">0.0.2&nbsp;&nbsp;</span>Another variables take from kaggle (frequency of the question) ### ELIMINATED</a></div><div class=\"lev3 toc-item\"><a href=\"#Using-pyenchant-to-correct-misspelled\" data-toc-modified-id=\"Using-pyenchant-to-correct-misspelled-003\"><span class=\"toc-item-num\">0.0.3&nbsp;&nbsp;</span>Using pyenchant to correct misspelled</a></div><div class=\"lev3 toc-item\"><a href=\"#Conclusione:-NON-CORREGGERE-NIENTE\" data-toc-modified-id=\"Conclusione:-NON-CORREGGERE-NIENTE-004\"><span class=\"toc-item-num\">0.0.4&nbsp;&nbsp;</span>Conclusione: NON CORREGGERE NIENTE</a></div><div class=\"lev3 toc-item\"><a href=\"#Train-Logit-Model\" data-toc-modified-id=\"Train-Logit-Model-005\"><span class=\"toc-item-num\">0.0.5&nbsp;&nbsp;</span>Train Logit Model</a></div><div class=\"lev3 toc-item\"><a href=\"#Tentativi-di-Tagger\" data-toc-modified-id=\"Tentativi-di-Tagger-006\"><span class=\"toc-item-num\">0.0.6&nbsp;&nbsp;</span>Tentativi di Tagger</a></div><div class=\"lev3 toc-item\"><a href=\"#Proprietà-transitiva:-q-è-duplicata-di-B-e-anche-di-C-allora-B-e-C-sono-tra-loro-duplicati\" data-toc-modified-id=\"Proprietà-transitiva:-q-è-duplicata-di-B-e-anche-di-C-allora-B-e-C-sono-tra-loro-duplicati-007\"><span class=\"toc-item-num\">0.0.7&nbsp;&nbsp;</span>Proprietà transitiva: q è duplicata di B e anche di C allora B e C sono tra loro duplicati</a></div><div class=\"lev3 toc-item\"><a href=\"#Check-number-of-1's-in-the-test-on-the-LB-using-logloss-value-for-a-fixed-prediction-probability\" data-toc-modified-id=\"Check-number-of-1's-in-the-test-on-the-LB-using-logloss-value-for-a-fixed-prediction-probability-008\"><span class=\"toc-item-num\">0.0.8&nbsp;&nbsp;</span>Check number of 1's in the test on the LB using logloss value for a fixed prediction probability</a></div><div class=\"lev3 toc-item\"><a href=\"#creazione-tagger_counter\" data-toc-modified-id=\"creazione-tagger_counter-009\"><span class=\"toc-item-num\">0.0.9&nbsp;&nbsp;</span>creazione tagger_counter</a></div><div class=\"lev3 toc-item\"><a href=\"#Tuning-w2v\" data-toc-modified-id=\"Tuning-w2v-0010\"><span class=\"toc-item-num\">0.0.10&nbsp;&nbsp;</span>Tuning w2v</a></div><div class=\"lev3 toc-item\"><a href=\"#Create-data-for-cluster\" data-toc-modified-id=\"Create-data-for-cluster-0011\"><span class=\"toc-item-num\">0.0.11&nbsp;&nbsp;</span>Create data for cluster</a></div><div class=\"lev3 toc-item\"><a href=\"#Ensamble-stuff\" data-toc-modified-id=\"Ensamble-stuff-0012\"><span class=\"toc-item-num\">0.0.12&nbsp;&nbsp;</span>Ensamble stuff</a></div><div class=\"lev4 toc-item\"><a href=\"#NN-xgb-ensemble\" data-toc-modified-id=\"NN-xgb-ensemble-00121\"><span class=\"toc-item-num\">0.0.12.1&nbsp;&nbsp;</span>NN-xgb ensemble</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shannon Entropy of the phrase: as expected it didn't work ---> removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(string):\n",
    "    \"Calculates the Shannon entropy of a string\"\n",
    "    # get probability of chars in string\n",
    "    prob = [\n",
    "        0 if len(string)==0 else\n",
    "        float(string.count(c)) / len(string)\n",
    "        for c in dict.fromkeys(list(string))\n",
    "    ]\n",
    "    # calculate the entropy\n",
    "    entropy = -sum([p * np.log(p) / np.log(2.0) for p in prob])\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def entropy_ideal(length):\n",
    "    \"Calculates the ideal Shannon entropy of a string with given length\"\n",
    "    prob = 0.0000001 if length == 0 else 1.0 / length\n",
    "    return -1.0 * length * prob * np.log(prob) / np.log(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['entropy1'] = train_df.apply(axis=1, func=lambda x:entropy(x['question1']))\n",
    "train_df['entropy2'] = train_df.apply(axis=1, func=lambda x:entropy(x['question2']))\n",
    "\n",
    "train_df['entropy_ideal1'] = train_df.apply(axis=1, func=lambda x:entropy_ideal(len(x['question1'])))\n",
    "train_df['entropy_ideal2'] = train_df.apply(axis=1, func=lambda x:entropy_ideal(len(x['question2'])))\n",
    "\n",
    "train_df['diff_entropy1'] = train_df['entropy_ideal1'] - train_df['entropy1']\n",
    "train_df['diff_entropy2'] = train_df['entropy_ideal2'] - train_df['entropy2']\n",
    "\n",
    "train_df['diff_entropy_diff'] = np.abs(train_df['diff_entropy1'] - train_df['diff_entropy2'])\n",
    "\n",
    "train_df['diff_entropy'] = np.abs(train_df['entropy1'] - train_df['entropy2'])\n",
    "train_df['diff_entropy_ideal'] = np.abs(train_df['entropy_ideal1'] - train_df['entropy_ideal2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['entropy1'] = test_df.apply(axis=1, func=lambda x:entropy(x['question1']))\n",
    "test_df['entropy2'] = test_df.apply(axis=1, func=lambda x:entropy(x['question2']))\n",
    "test_df['entropy_ideal1'] = test_df.apply(axis=1, func=lambda x:entropy_ideal(len(x['question1'])))\n",
    "test_df['entropy_ideal2'] = test_df.apply(axis=1, func=lambda x:entropy_ideal(len(x['question2'])))\n",
    "test_df['diff_entropy1'] = test_df['entropy_ideal1'] - test_df['entropy1']\n",
    "test_df['diff_entropy2'] = test_df['entropy_ideal2'] - test_df['entropy2']\n",
    "test_df['diff_entropy_diff'] = np.abs(test_df['diff_entropy1'] - test_df['diff_entropy2'])\n",
    "test_df['diff_entropy'] = np.abs(test_df['entropy1'] - test_df['entropy2'])\n",
    "test_df['diff_entropy_ideal'] = np.abs(test_df['entropy_ideal1'] - test_df['entropy_ideal2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Another variables take from kaggle (frequency of the question) ### ELIMINATED ####\n",
    "- https://www.kaggle.com/jturkewitz/magic-features-0-03-gain\n",
    "- calculate the frequencies of a question in the dataframe and saving them into a dictionary\n",
    "- add a features which is how many times the questions occurred using the previous dictionary for both q1 and q2\n",
    "- here we are using both test and train questions to get more stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "d_freq = Counter(\n",
    "    test_df.question1.append([\n",
    "        test_df.question2, train_df.question1, train_df.question2\n",
    "    ]).reset_index(drop=True).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['q1_freq'] = train_df.apply(axis=1, func=lambda x: d_freq[x['question1']])\n",
    "train_df['q2_freq'] = train_df.apply(axis=1, func=lambda x: d_freq[x['question2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using pyenchant to correct misspelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def flatmap(f, items):\n",
    "    return chain.from_iterable(map(f, items))\n",
    "\n",
    "def get_words(x):\n",
    "    return remove_punctuations(x).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "all_unique_quests = set(\n",
    "    list(set(train_df['question1'])) + list(set(train_df['question2'])) +\n",
    "    list(set(test_df['question1'])) + list(set(test_df['question2'])))\n",
    "all_words = flatmap(get_words, all_unique_quests)\n",
    "cnt_words = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(cnt_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = cnt_words.most_common(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en = enchant.Dict('en_US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0-1 -100, -1):\n",
    "    if not sum([c.isupper() for c in a[i][0]]):\n",
    "        print(a[i], en.suggest(a[i][0]), sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d = enchant.DictWithPWL(\"en_US\", \"../../Documents/myDataScience/Data_nlp/mywords.txt\")\n",
    "d = enchant.DictWithPWL(\"en_US\")\n",
    "chkr = SpellChecker(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per correggere per bene servirebbe:\n",
    "- lista nomi film\n",
    "- lista recenti parole inglesi tipo app, sms\n",
    "- buzz words del momento tipo bitcoin\n",
    "- lista siti internet\n",
    "- elenco città del mondo\n",
    "- chi più ne ha più ne metta\n",
    "\n",
    "forse conbiene mettere tutta la lista di parole su cui ha trainato google? però gli errori li c'erano\n",
    "\n",
    "anche usare le parole più frequenti della chat non va bene\n",
    "\n",
    "### Conclusione: NON CORREGGERE NIENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fanboys\n",
    "['fan boys', 'fan-boys', 'Sanborn', 'Barnabas', 'cannabis']\n",
    "screenshot\n",
    "['screen shot', 'screen-shot', 'screens hot', 'screens-hot', 'screenwriter', 'touchscreen', 'sunscreen', 'screene\n",
    "bootloader\n",
    "['boot loader', 'boot-loader', 'bootlegger', 'autoloader', 'boatload', 'reloader', 'bootlaces', 'bootlegged']\n",
    "\n",
    "## cosa farci? lui vorrebbe o separale o metterci - nel mezzo, dovrei chiedere di non separare mai le parole?\n",
    "## attualmente stiamo sostituendo gli - con spazi, ma la gente non scrive con - in genere\n",
    "## conclusione: corregge molte parole scritte male (e ci sono) però ammazza parole che sono uniche e quindi\n",
    "## dovrebbero parlare molto della frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "india\n",
      "['India', 'indie', 'Indian', 'Indira', 'Ind', 'ind', 'Indy', 'Oneida', 'Indra', 'Inuit', 'innit', 'Indies', 'indies', 'Nadia', 'Enid', 'Anita', 'Ida', 'Ina', \"India's\", 'Indiana', 'indigo', 'indite', 'indium', 'and', 'end', 'int', 'Hindi', 'Linda', 'kinda', 'idea'] \n",
      "\n",
      "\n",
      "Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?\n",
      "quikly\n",
      "['quickly', 'quill', 'quirky', 'quietly', 'quaky', 'quail', 'quick', 'quirk', 'wkly', 'luckily', 'murkily', 'gully', 'quell', 'likely', 'quirks', 'sickly', 'July', 'giggly', 'jiggly', 'squiggly', 'cockily', 'gawkily', 'jerkily', 'ugly', 'queerly', 'quicker', 'quickie', 'cagily', \"quick's\", \"quirk's\", 'Aquila', 'curly', 'gaily', 'girly', 'guile', 'quake'] \n",
      "\n",
      "\n",
      "Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?\n",
      "di\n",
      "['DI', 'Di', 'DUI', 'Dir', 'Du', 'die', 'do', 'ID', 'id', 'D', 'd', 'DWI', 'Dis', 'did', 'dig', 'dim', 'din', 'dip', 'dis', 'div', 'Si', 'I', 'i', 'Dix', 'DA', 'DD', 'DE', 'Dy', 'Ti', 'dd', 'ti', 'SDI', 'DC', 'DH', 'DJ', 'DP', 'Dr', 'dB', 'db', 'dc', 'dz', 'AI', 'Bi', 'Ci', 'GI', 'HI', 'Li', 'MI', 'Ni', 'RI', 'VI'] \n",
      "\n",
      "\n",
      "Should I buy tiago?\n",
      "tiago\n",
      "['ti ago', 'ti-ago', 'Iago', 'Togo', 'Tia', 'ago', 'tag', 'taiga', 'ciao', 'GIGO', 'dago', 'sago', 'taco', 'shag', 'Riga', 'toga', 'Diego', \"Tia's\", 'Virgo', 'tiara', 'GAO', 'rigor', 'tog', 'Argo', 'Igor', 'rag', 'rig', 'tug', 'go', 'Ag', 'biog', 'Fargo', 'Magoo', 'Margo', 'Taegu', 'cargo', 'ciaos', 'largo', 'tiger', 'vigor', 'CIA', 'Chicago', 'KIA', 'MiG', 'Paige', 'TKO', 'age', 'bag', 'big', 'cigar', 'dag', 'dig', 'ego', 'fag', 'fig', 'gag', 'gig', 'hag', 'jag', 'jig', 'lag', 'mag', 'nag', 'pig', 'sag', 'tic', 'wag', 'wig', 'chg'] \n",
      "\n",
      "\n",
      "Method to find separation of slits using fresnel biprism?\n",
      "fresnel\n",
      "['Fresnel', \"Fresnel's\", 'Fresno'] \n",
      "\n",
      "\n",
      "Method to find separation of slits using fresnel biprism?\n",
      "biprism\n",
      "['bi prism', 'bi-prism', 'prism', 'baptism', 'purism'] \n",
      "\n",
      "\n",
      "Which is the best digital marketing institution in banglore?\n",
      "banglore\n",
      "['Bangalore', 'bang lore', 'bang-lore', 'bangle', 'bangles', 'bungler', 'bungle', 'bunghole', 'bunglers', \"bangle's\", \"bungler's\"] \n",
      "\n",
      "\n",
      "What is the best travel website in spain?\n",
      "spain\n",
      "['Spain', 'spa in', 'spa-in', 'Span', 'span', 'spin', 'Spahn', 'spawn', 'spine', 'spiny', 'spun', 'spavin', 'sprain', 'pain', 'spoon', 'slain', 'stain', 'swain', 'spurn', \"Spain's\"] \n",
      "\n",
      "\n",
      "Who is israil friend?\n",
      "israil\n",
      "['is rail', 'is-rail', 'Israel', 'Israeli', 'Ismail', 'Israels', 'assail', 'Ismael', \"Israel's\"] \n",
      "\n",
      "\n",
      "How do I download content from a kickass torrent without registration?\n",
      "kickass\n",
      "['kick ass', 'kick-ass', 'kicks', 'jackass', \"kick's\", 'kickers', 'kikes', \"kicker's\", \"Keck's\", \"jackass's\", \"Hicks's\"] \n",
      "\n",
      "\n",
      "What were the major effects of the cambodia earthquake, and how do these effects compare to the Kamchatca earthquakes in 1952?\n",
      "cambodia\n",
      "['Cambodia', 'Cambodian', \"Cambodia's\"] \n",
      "\n",
      "\n",
      "What is the best reference book for physics class 11th?\n",
      "th\n",
      "['Th', 'Thu', 'the', 'tho', 'thy', 'THC', 'Rh', 'HT', 'ht', 'H', 'T', 'h', 't', 'nth', 'Ch', 'OH', 'TA', 'Ta', 'Te', 'Ti', 'Tu', 'Ty', 'ah', 'ch', 'eh', 'oh', 'pH', 'sh', 'ta', 'ti', 'to', 'uh', 'DH', 'NH', 'TB', 'TD', 'TM', 'TN', 'TV', 'TX', 'Tb', 'Tc', 'Tl', 'Tm', 'tn', 'tr', 'ts', \"Th's\", \"T's\"] \n",
      "\n",
      "\n",
      "Why did harry become a horcrux?\n",
      "horcrux\n",
      "['Crux', 'crux', 'Gacrux', 'Acrux', 'crocus'] \n",
      "\n",
      "\n",
      "Will the recent demonetisation results in higher GDP? If so how much?\n",
      "demonetisation\n",
      "['demonetization', \"demonetization's\", 'demagnetization', 'demonstration'] \n",
      "\n",
      "\n",
      "Where can I watch gonulcelen with english subtitles?\n",
      "gonulcelen\n",
      "['concealing', 'counseling', 'canceling', 'gunslinger', 'consoling'] \n",
      "\n",
      "\n",
      "Where can I watch gonulcelen with english subtitles?\n",
      "english\n",
      "['English', 'Englisher', \"English's\", 'Englishes'] \n",
      "\n",
      "\n",
      "Why my question was marked as needing imrovement?\n",
      "imrovement\n",
      "['improvement', 'improvements', 'movement', \"improvement's\"] \n",
      "\n",
      "\n",
      "What are some yakshini mantras?\n",
      "yakshini\n",
      "['cashing', 'gashing', 'yakking', 'quashing', 'yoking', 'caching', 'coshing', 'gushing', 'joshing', 'yukking'] \n",
      "\n",
      "\n",
      "Are exocytosis and endocytosis examples of active or passive transport?\n",
      "exocytosis\n",
      "[\"Exocet's\", 'exorcists', 'exorcises', 'excises', 'ecstasies', 'exoduses', 'excites', \"exorcist's\", 'excesses', 'exciters', \"excise's\", 'exists', \"exciter's\", 'exercises', 'exceeds', \"expertise's\", \"ecstasy's\", \"exercise's\"] \n",
      "\n",
      "\n",
      "Are exocytosis and endocytosis examples of active or passive transport?\n",
      "endocytosis\n",
      "['antisepsis', 'industries', 'understudies', 'industrious', 'indecencies', 'undecideds', 'antacids', 'undersides', \"undecided's\", 'interstices', \"antacid's\", \"industry's\", \"indecency's\", 'understates', 'intercessors', \"intestacy's\", \"understudy's\", \"interstice's\", \"underside's\", \"antisepsis's\", \"intercessor's\"] \n",
      "\n",
      "\n",
      "How do I find a startup accelerator?\n",
      "startup\n",
      "['start up', 'start-up', 'start', 'stirrup', 'statue', 'starts', 'status', 'starter', \"start's\", 'started', 'startle', 'strap', 'Stuart', 'setup', 'statute', 'strip', 'starting', 'stat', 'satrap', 'Stuarts', 'static', 'statues', 'stature', 'state', 'stoup', 'stamp', 'stats', 'strep', 'strop', \"Stuart's\", 'starters', 'stater', 'Staten', 'States', \"stat's\", 'stated', 'states', \"state's\", \"statue's\", \"status's\", \"starter's\"] \n",
      "\n",
      "\n",
      "How can I check wifi history and access it through android phones?\n",
      "wifi\n",
      "['Wii', 'wife', 'wiki'] \n",
      "\n",
      "\n",
      "How do you take a screenshot on a Mac laptop?\n",
      "screenshot\n",
      "['screen shot', 'screen-shot', 'screens hot', 'screens-hot', 'screens', 'screened', 'screeched', \"screen's\", 'scrunched', 'screen', 'serenest', 'screechy', 'screech', 'scrunchy', 'screenwriter', 'scrunch', \"screech's\", 'screeches', 'screening', \"scrunch's\"] \n",
      "\n",
      "\n",
      "What are the effects of demonitization of 500 and 1000 rupees notes on real estate sector?\n",
      "demonitization\n",
      "['demonetization', \"demonetization's\", 'demobilization', 'demagnetization', 'democratization', 'desensitization', 'demonstration'] \n",
      "\n",
      "\n",
      "Why are women who are on their periods are regarded as 'unclean' such that they are prevented in taking an actived part in rituals (Hinduism)?\n",
      "actived\n",
      "['actives', 'active', 'activate', \"active's\", 'acted', 'activated', 'actively', 'activity'] \n",
      "\n",
      "\n",
      "Do inkjet printers use color ink when printing black and white documents? If so, why?\n",
      "inkjet\n",
      "['ink jet', 'ink-jet', 'inject', 'inkiest', 'inked', 'anklet', 'injects', 'injector', 'infect', 'ingest', 'insect', 'inquest', 'oinked', 'ingot'] \n",
      "\n",
      "\n",
      "What is my puk code?\n",
      "puk\n",
      "['Puck', 'puck', 'puke', 'pk', 'punk', 'Pu', 'UK', 'pug', 'auk', 'pub', 'pud', 'pun', 'pup', 'pus', 'put', 'yuk', \"Pu's\"] \n",
      "\n",
      "\n",
      "How do you feel when someone upvotes your answer on Quora?\n",
      "upvotes\n",
      "['up votes', 'up-votes', 'outvotes', 'pivots', 'updates', \"pivot's\", 'invites', 'upsets', 'uproots', 'upshots', \"Epcot's\", \"update's\", \"upshot's\", 'upsides', \"invite's\", 'opiates', 'uploads', \"upset's\", \"upside's\", \"opiate's\"] \n",
      "\n",
      "\n",
      "How far would you go for love? Should I wait for the one I love ir move on?\n",
      "ir\n",
      "['Ir', 'IE', 'OR', 'Ur', 'or', 'RI', 'I', 'i', 'IRA', 'IRS', 'IT', 'Ira', 'It', 'ire', 'irk', 'it', 'air', 'R', 'r', 'AR', 'Ar', 'ER', 'Er', 'IA', 'Ia', 'Io', 'er', 'ii', 'Dir', 'Mir', 'Sir', 'cir', 'fir', 'sir', 'ID', 'IL', 'IN', 'IQ', 'IV', 'In', 'id', 'if', 'in', 'is', 'iv', 'ix', 'RR', 'yr', 'BR', 'Br', 'Cr', 'Dr'] \n",
      "\n",
      "\n",
      "When travelling to a new region is it better to immerse yourself in 1–2 cities or to see as many cities as you can cram in?\n",
      "travelling\n",
      "['travel ling', 'travel-ling', 'traveling', 'travailing', 'travelings', 'raveling', 'graveling', 'driveling', 'grovelling', 'traversing', 'trawling', \"traveling's\", 'reveling', 'trailing', 'trilling', 'trolling'] \n",
      "\n",
      "\n",
      "What would be the estimated cost of repairing the cracked screen of iphone 6?\n",
      "iphone\n",
      "['iPhone', 'phone', 'siphon', 'phony', 'earphone'] \n",
      "\n",
      "\n",
      "Should I repeat 2nd year in college, or find a new college? It's a 5 year course.\n",
      "nd\n",
      "['ND', 'Nd', 'Ned', 'nod', 'MD', 'Md', 'NF', 'NS', 'D', 'N', 'd', 'n', 'NT', 'Ind', 'and', 'end', 'ind', 'DD', 'NE', 'NW', 'NY', 'Na', 'Ne', 'Ni', 'No', 'dd', 'no', 'nu', 'yd', 'AD', 'CD', 'Cd', 'Ed', 'FD', 'Gd', 'ID', 'JD', 'NB', 'NC', 'NH', 'NJ', 'NM', 'NP', 'NR', 'NV', 'NZ', 'Nb', 'Np', 'OD', 'PD'] \n",
      "\n",
      "\n",
      "I wish to simulate a fake location for an app running on my iOS device. How do you fake a GPS location for iOS without jailbreaking as a non-coder?\n",
      "jailbreaking\n",
      "['jail breaking', 'jail-breaking', 'jailbreak', 'jailbreaks', 'lawbreaking', \"jailbreak's\", 'calibrating'] \n",
      "\n",
      "\n",
      "Which is the best programing language for tcs?\n",
      "programing\n",
      "['programming', 'programmings', \"programming's\", 'program', 'progressing', 'deprogramming', 'reprogramming', 'programs', 'proclaiming', 'procreating', \"program's\", 'programmer', 'programmed', 'procuring'] \n",
      "\n",
      "\n",
      "Which is the best programing language for tcs?\n",
      "tcs\n",
      "[\"Tc's\", 'tics', 'TVs', 'Cs', 'Tc', 'cs', 'ts', \"T's\", 'JCS', 'PCs', 'tbs', \"tic's\", \"TLC's\", \"TV's\", \"C's\", \"CT's\", \"DC's\", \"Ta's\", \"Te's\", \"Ti's\", \"Ty's\", \"ti's\", \"AC's\", \"Ac's\", \"BC's\", \"PC's\", \"SC's\", \"Sc's\", \"TB's\", \"Tb's\", \"Tl's\", \"Tm's\", \"Th's\"] \n",
      "\n",
      "\n",
      "What is the VTU 1st sem exam time table of 2016 (Dec)?\n",
      "sem\n",
      "['seam', 'seem', 'semi', 'Sm', 'stem', 'Dem', 'Sen', 'sen', 'SE', 'Se', 'EM', 'em', 'SAM', 'Sam', 'sum', 'sea', 'see', 'sew', 'REM', 'SEC', 'Sec', 'Set', 'fem', 'gem', 'hem', 'rem', 'sec', 'seq', 'set', 'sex', \"SE's\", \"Se's\"] \n",
      "\n",
      "\n",
      "How do I send message from one Android phone to another Android phone through bluetooth?\n",
      "bluetooth\n",
      "['Bluetooth', 'blue tooth', 'blue-tooth', \"Bluetooth's\"] \n",
      "\n",
      "\n",
      "What are some examples of deuteromycota and how are they formed?\n",
      "deuteromycota\n",
      "['detract', 'detractor', 'detriment'] \n",
      "\n",
      "\n",
      "How do I find the zeros of the polynomial function [math]f(x)=\\dfrac{1}{2}x^{3}-3x[/math]?\n",
      "dfrac\n",
      "['Dirac', 'Draco', 'defrock', 'defray', 'Dvorak', 'drag', 'frag', 'Doric', 'Duroc', 'diffract', 'Africa', 'defraud', 'defrays', 'Drake', 'drake', 'freak', 'frock', 'track', 'Derick', 'drug', 'freq', 'frig', 'frog'] \n",
      "\n",
      "\n",
      "Can you debeak cockerels at 8 months old?\n",
      "debeak\n",
      "['debark', 'Debra', 'beak', 'debar', 'Derek', 'debarks', 'debug', 'debunk', 'Debian', 'Debora', 'dybbuk', 'Debs', 'debars', 'debs', 'desk', 'daybreak', 'deb', 'tieback', 'Dubcek', 'deejay', \"deb's\", 'debase', 'debate', 'Rebekah', 'Beck', 'beck', 'berk', 'deck', 'teabag', 'teak', 'tiebreak', 'Reebok', 'debt', 'Debby', 'Decca', 'Dubai', 'decay', 'bedeck'] \n",
      "\n",
      "\n",
      "Which car has good build quality in india?\n",
      "india\n",
      "['India', 'indie', 'Indian', 'Indira', 'Ind', 'ind', 'Indy', 'Oneida', 'Indra', 'Inuit', 'innit', 'Indies', 'indies', 'Nadia', 'Enid', 'Anita', 'Ida', 'Ina', \"India's\", 'Indiana', 'indigo', 'indite', 'indium', 'and', 'end', 'int', 'Hindi', 'Linda', 'kinda', 'idea'] \n",
      "\n",
      "\n",
      "Why are my bestfriend still ignoring me?\n",
      "bestfriend\n",
      "['best friend', 'best-friend', 'befriend', 'boyfriend', 'bestirred', 'bestrewn', 'bestride', 'restrained', 'bestridden', 'bestirring', 'bestrewed', 'bestriding', 'Bertrand'] \n",
      "\n",
      "\n",
      "How many sponsored candidates are shortlisted for CMC vellore?\n",
      "vellore\n",
      "['velour', 'Valerie', 'Valarie', 'Velcro', 'Weller', 'lore', 'wellie', 'velours', 'valor', 'velar', 'Villon', 'allure', 'galore', 'velars', 'vellum', 'Valery', 'Loire', 'Lorie', 'Lorre', 'lire', 'verier', 'wore', 'vulture', 'welfare', 'Mallory', 'pillory', 'verdure', 'village', \"velour's\", 'viler', 'Elroy', 'valley', 'volley', 'Lora', 'Lori', 'Vela', 'Waller', 'lure', 'lyre', 'valuer', 'veal', 'veil', 'vela', 'well', 'were', \"valor's\", \"velar's\", \"we're\", \"Weller's\", \"we'll\"] \n",
      "\n",
      "\n",
      "I argued with my gf that she made friends with the person that hit on her. She said I'm a control freak and she wants her freedom. What should I do?\n",
      "gf\n",
      "['ff', 'Gd', 'HF', 'Hf', 'hf', 'F', 'G', 'f', 'g', 'CF', 'Cf', 'cf', 'GA', 'GE', 'GI', 'GU', 'Ga', 'Ge', 'go', 'AF', 'GB', 'GM', 'GP', 'Gk', 'Gr', 'NF', 'RF', 'Rf', 'SF', 'VF', 'bf', 'gm', 'gr', 'gs', 'gt', 'if', 'of', 'pf', 'sf', \"G's\"] \n",
      "\n",
      "\n",
      "Is it true that in order to be part of an elite or just rich and successful, you have to join a secret organisation otherwise no chance at all?\n",
      "organisation\n",
      "['organization', 'organizations', \"organization's\", 'organizational', 'reorganization'] \n",
      "\n",
      "\n",
      "Why is sandeep maheshwari not on Quora?\n",
      "sandeep\n",
      "['sander', 'Sanders', 'sanders', 'sanded', 'sandier', 'Sand', 'Saunders', 'sand', \"sander's\", 'sender', 'sunder', 'Sandra', 'Sandy', 'sandy', 'steep', 'sands', 'sundae', \"sand's\", 'sandal', 'sandpit', \"Sandy's\"] \n",
      "\n",
      "\n",
      "Why is sandeep maheshwari not on Quora?\n",
      "maheshwari\n",
      "['Maharashtra', 'hardware', 'dishware', 'Mahavira', 'hatchway', 'Manchuria', 'hatchways', 'hatchery', 'showery', 'matchwood', 'haywire', \"hatchway's\"] \n",
      "\n",
      "\n",
      "What are some cute shounen ai series?\n",
      "shounen\n",
      "['shone', 'showmen', 'shorten', 'Shannon', 'shine', 'shining', 'shown', 'shogun', 'shunned', 'shun', 'shiner', 'shinning', 'shined', 'shines', 'shrine', 'Shane', 'Shaun', 'sheen', 'shuns', 'shunt', 'Shriner', 'shinned', 'shouting', 'showman', 'Shauna', 'chosen', 'shaken', 'shaven', 'Shawnee', \"Shaun's\", 'sharpen', 'shebeen', \"shine's\", \"Shane's\", \"Shauna's\"] \n",
      "\n",
      "\n",
      "What are some cute shounen ai series?\n",
      "ai\n",
      "['AI', 'IA', 'Ia', 'Au', 'air', 'A', 'I', 'a', 'i', 'AIs', 'Ali', 'aid', 'ail', 'aim', 'Si', 'AA', 'AR', 'Ar', 'ah', 'aw', 'ii', 'oi', 'CAI', 'Mai', 'AB', 'AC', 'AD', 'AF', 'AK', 'AL', 'AM', 'AP', 'AV', 'AZ', 'Ac', 'Ag', 'Al', 'Am', 'As', 'At', 'Av', 'ab', 'ac', 'ad', 'am', 'an', 'as', 'at', 'av', 'ax'] \n",
      "\n",
      "\n",
      "What is an actinomorphic flower?\n",
      "actinomorphic\n",
      "['autonomic', 'agronomic', 'economic', 'actinium', \"actinium's\", 'ergonomic', 'academic'] \n",
      "\n",
      "\n",
      "What words rank the highest on Dictionary.com's difficulty index?\n",
      "com's\n",
      "[\"coma's\", \"come's\", \"corm's\", \"Cm's\", \"Qom's\", \"cam's\", 'comas', 'comes', \"cum's\", \"comma's\", 'corms', \"comb's\", \"comp's\", \"comer's\", \"con's\", \"CO's\", \"Co's\", \"Jim's\", \"Kim's\", 'comers', 'commas', \"om's\", 'cams', 'cums', 'Combs', \"Coy's\", 'combs', 'comps', \"coo's\", \"cos's\", \"cow's\", \"ROM's\", \"Tom's\", \"cob's\", \"cod's\", \"cog's\", \"cop's\", \"cot's\", \"mom's\", \"tom's\", 'Camus', \"gem's\", \"gum's\", \"gym's\", \"jam's\", 'coma', 'cons', 'Com', 'com', 'cos', 'oms', 'Como', 'comb', 'come', 'comm', 'coos'] \n",
      "\n",
      "\n",
      "How many minutes of cardio a day should I do?\n",
      "cardio\n",
      "['cardie', 'card', 'Cardin', 'caddie', 'carder', 'Cardozo', 'Cato', 'radio', 'CAD', 'Casio', 'cad', 'Cardiff', 'Claudio', 'cardiac', 'cardies', 'carding', 'cart', 'cord', 'curd', 'Cadiz', 'Cartier', 'cards', 'Carlo', 'audio', 'cargo', 'carpi', 'curio', \"card's\", 'carded'] \n",
      "\n",
      "\n",
      "Who do I activate the dlc of skyrim in a laptop? Ive got it working on my computer after doing the command lines, but did the same on laptop, to no use..\n",
      "dlc\n",
      "['LDC', 'DC', 'LC', 'dc', 'TLC', 'DEC', 'Dec', 'doc'] \n",
      "\n",
      "\n",
      "Who do I activate the dlc of skyrim in a laptop? Ive got it working on my computer after doing the command lines, but did the same on laptop, to no use..\n",
      "skyrim\n",
      "['sky rim', 'sky-rim', 'scrim', 'scrum', 'skim', 'sacrum', 'scram', 'strum', 'squirm', 'Sikkim', 'scrimp', 'scrims', 'serum', 'grim', 'scream', 'Seagram', 'scrip', \"scrim's\"] \n",
      "\n",
      "\n",
      "Where do I find 3ds emulator for android?\n",
      "ds\n",
      "[\"D's\", 'DOS', 'Dis', 'dis', 'dos', 'SD', 'DA', 'DD', 'DPs', 'DST', 'SS', 'dd', 'DDS', 'dds', 'D', 'S', 'd', 's', 'dz', 'ts', 'IDs', 'ODs', 'ads', 'eds', 'ids', 'DE', 'DI', 'Di', 'Du', 'Dy', 'do', 'As', 'BS', 'Cs', 'DC', 'DH', 'DJ', 'DP', 'Dr', 'Es', 'HS', 'KS', 'Ks', 'MS', 'Ms', 'NS', 'OS', 'Os', 'PS'] \n",
      "\n",
      "\n",
      "Is it necessary to unlock bootloader before rooting Android phones?\n",
      "bootloader\n",
      "['boot loader', 'boot-loader', 'boatload', 'bootlace', 'boatloads', 'bottled', 'bootlegger', 'bolder', 'Boulder', 'bloater', 'bottler', 'boulder'] \n",
      "\n",
      "\n",
      "What is bss engineer?\n",
      "bss\n",
      "[\"BS's\", 'BSA', 'Bass', 'Bess', 'bass', 'boss', 'buss', 'BS', 'BSD', 'SS', 'BSDs', \"B's\", 'BBS', 'bis', 'bus', 'SSS', 'bps', 'bxs', 'USS', 'ass', \"BA's\", \"Ba's\", \"bus's\", \"S's\", \"Sb's\", \"Be's\", \"Bi's\", \"bi's\", \"by's\", \"PBS's\", \"UBS's\", \"abs's\", \"BC's\", \"BM's\", \"Bk's\", \"Br's\", \"MS's\", \"OS's\", \"PS's\", \"US's\", \"BB's\"] \n",
      "\n",
      "\n",
      "Is it possible to do CA after 12th Science?\n",
      "th\n",
      "['Th', 'Thu', 'the', 'tho', 'thy', 'THC', 'Rh', 'HT', 'ht', 'H', 'T', 'h', 't', 'nth', 'Ch', 'OH', 'TA', 'Ta', 'Te', 'Ti', 'Tu', 'Ty', 'ah', 'ch', 'eh', 'oh', 'pH', 'sh', 'ta', 'ti', 'to', 'uh', 'DH', 'NH', 'TB', 'TD', 'TM', 'TN', 'TV', 'TX', 'Tb', 'Tc', 'Tl', 'Tm', 'tn', 'tr', 'ts', \"Th's\", \"T's\"] \n",
      "\n",
      "\n",
      "How can I hack someones whatsapp account?\n",
      "whatsapp\n",
      "['whats app', 'whats-app', 'whats', 'whatsit', \"what's\", 'WASP', 'WATS', 'wasp', 'Watson', 'whets', 'whits', 'whitecap', \"WATS's\", \"wheat's\", 'Watts', 'waits', 'warts', 'watts', 'Winesap', 'Watusi', 'Whites', \"whit's\", 'whites', 'vats', 'wads', 'wets', 'wits', \"wait's\", \"wart's\", \"watt's\", \"VAT's\", \"White's\", \"vat's\", \"wad's\", \"wet's\", \"white's\", \"wit's\"] \n",
      "\n",
      "\n",
      "What is your favourite anime character and why?\n",
      "favourite\n",
      "['favorite', 'favorites', 'favored', \"favorite's\", 'fluorite'] \n",
      "\n",
      "\n",
      "What is your favourite anime character and why?\n",
      "anime\n",
      "['anise', 'Annie', 'Amie', 'anemia', 'name', 'Aimee', 'Anne', 'Nome', 'Angie', 'Annam', 'aim', 'animate', 'anytime', 'animal', 'animus', 'gnome', 'anode', 'acme', 'ante', 'airmen', 'Anita', 'Niamey', 'anion', 'unite', 'Nam', 'Amen', 'amen', 'enema', 'enemy', 'Amer', 'Arnhem', 'anemic', 'anew', 'anthem', 'AM', 'Ainu', 'Am', 'NM', 'am', 'an', \"I'm\"] \n",
      "\n",
      "\n",
      "How do I start a solar energy business in egypt?\n",
      "egypt\n",
      "['Egypt', \"Egypt's\"] \n",
      "\n",
      "\n",
      "Can my PC with specs 2 GB DDR2@ RAM, Intel Core Duo 3.5 GHz, NVidia GeForce GT 610 3gb DDR3 run Assassin's Creed Syndicate and GTA V?\n",
      "gb\n",
      "['GB', 'gab', 'gob', 'B', 'G', 'b', 'g', 'CB', 'Cb', 'KB', 'Kb', 'QB', 'KGB', 'BB', 'GA', 'GE', 'GI', 'GU', 'Ga', 'Ge', 'Yb', 'go', 'AB', 'GM', 'GP', 'Gd', 'Gk', 'Gr', 'MB', 'Mb', 'NB', 'Nb', 'OB', 'Ob', 'Pb', 'Rb', 'Sb', 'TB', 'Tb', 'ab', 'dB', 'db', 'gm', 'gr', 'gs', 'gt', 'lb', 'ob', 'vb', \"GB's\"] \n",
      "\n",
      "\n",
      "Why India does not have friendly relations with it's neighbouring countries?\n",
      "neighbouring\n",
      "['neighboring', 'neighbored', 'Behring', 'boring', 'newborn', 'gibbering', 'numbering', 'neutering', 'nurturing', 'laboring', 'nibbling', 'burring', 'neuron', 'debarring', 'harboring', 'nickering', 'baring'] \n",
      "\n",
      "\n",
      "How do I find the phenotypic ratio?\n",
      "phenotypic\n",
      "['phenotype', 'phonetic', 'nitpick', 'nutpick', 'handpick', 'fanatic'] \n",
      "\n",
      "\n",
      "You have given all statement as correct in UNCCD question in CSE prelim 2016. While many coachings have taken 2nd statement as wrong.?\n",
      "coachings\n",
      "['catchings', 'coaching', 'caching', \"poaching's\", 'couching', 'coatings', 'teachings', 'touchings', \"coating's\", \"teaching's\"] \n",
      "\n",
      "\n",
      "You have given all statement as correct in UNCCD question in CSE prelim 2016. While many coachings have taken 2nd statement as wrong.?\n",
      "nd\n",
      "['ND', 'Nd', 'Ned', 'nod', 'MD', 'Md', 'NF', 'NS', 'D', 'N', 'd', 'n', 'NT', 'Ind', 'and', 'end', 'ind', 'DD', 'NE', 'NW', 'NY', 'Na', 'Ne', 'Ni', 'No', 'dd', 'no', 'nu', 'yd', 'AD', 'CD', 'Cd', 'Ed', 'FD', 'Gd', 'ID', 'JD', 'NB', 'NC', 'NH', 'NJ', 'NM', 'NP', 'NR', 'NV', 'NZ', 'Nb', 'Np', 'OD', 'PD'] \n",
      "\n",
      "\n",
      "Is it possible to turn off indicator light on a dahua camera?\n",
      "dahua\n",
      "['Doha', 'Dachau', 'dahlia', 'DH', 'dacha', 'Dhaka', 'aha', 'Bahia', 'Dada', 'Dana', 'Oahu', 'data', 'daub', 'dhow', 'Darla', 'sadhu', 'duh', 'Tahoe', 'Day', 'day', 'dash', 'dual', 'DA', 'Du', 'Ha', 'ha', 'Douay', 'HUD', 'hut', 'DAR', 'DEA', 'DOA', 'DUI', 'Donahue', 'Hui', 'due', 'duo', 'hue', 'huh', 'tau', 'Idaho', \"Doha's\"] \n",
      "\n",
      "\n",
      "How do I can stop hairfall?\n",
      "hairfall\n",
      "['hair fall', 'hair-fall', 'hairball', 'Haifa', \"Haifa's\", 'Harrell', 'airfoil', 'halal', 'Hamill', 'harmfully', 'Hill', 'fall', 'hill', 'harmful', 'airflow', 'befall', 'hardly', 'jarful', 'hatefully', 'hateful', 'highball', 'fairly', 'Rafael', 'barfly', 'earful', 'herbal', 'larval'] \n",
      "\n",
      "\n",
      "What is the opposite of \"homebird\"?\n",
      "homebird\n",
      "['home bird', 'home-bird', 'homebody', 'homeward', 'homered', 'homeboys', 'homed', 'homeboy', 'homburg', 'hominid', 'hombre', 'morbid', 'Lombard', 'bombard', \"homeboy's\", 'howbeit', 'Humberto', 'bombed', 'combed', 'hotbed', 'rhomboid', 'tombed', 'humid', \"homebody's\"] \n",
      "\n",
      "\n",
      "What are the good websites to learn C programming for begineer?\n",
      "begineer\n",
      "['beginner', 'begone', 'beguine', 'Begin', 'begin', 'beginners', 'bargainer', 'begun', 'begging', 'beguines', 'began', 'Ginger', \"beginner's\", 'begins', 'ginger', \"beguine's\"] \n",
      "\n",
      "\n",
      "How can I get MOOC/E-learning through online web and video courses related to filmmaking & production developed by Indian professors?\n",
      "filmmaking\n",
      "['film making', 'film-making', 'filming', 'flaking', 'filmmaker', 'flanking', 'flaming', 'filmmakers', 'flicking', 'flummoxing', 'lawmaking', 'flunking', 'Fleming', 'flecking', 'flocking', 'lovemaking', \"filmmaker's\"] \n",
      "\n",
      "\n",
      "Is there any way to get rid of gynecomastia?\n",
      "gynecomastia\n",
      "['genomes', 'gangsta', 'incomes', 'newcomers', 'noncoms', 'consortia', \"glaucoma's\", \"genome's\", \"noncom's\", \"newcomer's\", 'juncos', 'incomers', 'enigmas', \"junco's\", \"income's\", 'minicams', 'Banjarmasin', 'ginormous', 'condoms', \"enigma's\", \"condom's\", \"ginkgo's\", \"gingham's\", \"minicam's\"] \n",
      "\n",
      "\n",
      "What are the best available smartphones gadgets?\n",
      "smartphones\n",
      "['smart phones', 'smart-phones', 'smartens', 'smartness', 'symphonies', 'semitones', 'Stephens', 'smatterings', 'Sumatrans', \"semitone's\", \"symphony's\", \"Stephan's\", \"Sumatran's\", \"smartness's\", \"smattering's\", \"Stephanie's\"] \n",
      "\n",
      "\n",
      "Why hasn't Gayle Laakmann McDowell/careercup created a MOOC or a coding bootcamp?\n",
      "careercup\n",
      "['career cup', 'career-cup', 'crackup', 'creep', 'creepy', 'recoup', 'reequip', 'carrycot', 'Creek', 'creek', 'croup', 'correct', 'crackups', 'reoccupy', 'Creeks', 'creeks', 'creeper', 'crocus', 'preoccupy', 'crepe', 'Caracas', \"Creek's\", 'breakup', \"creek's\", 'Arequipa', 'crape', 'caregiver', 'Garrick', 'croupy', 'recopy', 'cracker', 'crapper', 'creepier', 'cracks', 'crackers', \"crackup's\", 'Crick', 'Greek', 'creak', 'crick', 'crock', 'group', \"cracker's\", \"crack's\"] \n",
      "\n",
      "\n",
      "Why hasn't Gayle Laakmann McDowell/careercup created a MOOC or a coding bootcamp?\n",
      "bootcamp\n",
      "['boot camp', 'boot-camp', 'bitmap', 'decamp', 'blowlamp', 'camp', 'tamp', 'boatman', 'scamp', 'stamp', 'tramp', 'bottom', 'became', 'toecap', 'doorjamb', 'encamp', 'bottoms', 'Bertram', 'outcome', 'outcrop', 'bookmark', 'bookshop', \"bottom's\", \"Bertram's\"] \n",
      "\n",
      "\n",
      "What is latency in telecom?\n",
      "telecom\n",
      "['talcum', 'telex', 'welcome', 'telegram', 'LCM', 'TLC', 'telecommute', 'Tacoma', 'talc', 'Holcomb', 'locum', \"TLC's\", 'Telugu', \"talc's\", \"talcum's\"] \n",
      "\n",
      "\n",
      "If you screenshot someone's Instagram video, will they get notified that you screenshotted it?\n",
      "screenshot\n",
      "['screen shot', 'screen-shot', 'screens hot', 'screens-hot', 'screens', 'screened', 'screeched', \"screen's\", 'scrunched', 'screen', 'serenest', 'screechy', 'screech', 'scrunchy', 'screenwriter', 'scrunch', \"screech's\", 'screeches', 'screening', \"scrunch's\"] \n",
      "\n",
      "\n",
      "If you screenshot someone's Instagram video, will they get notified that you screenshotted it?\n",
      "screenshotted\n",
      "['screens hotted', 'screens-hotted', 'screeched', 'scrunched', 'screenwriter', 'screenwriters', 'crenelated', \"screenwriter's\", 'scrimshawed'] \n",
      "\n",
      "\n",
      "What is the effect of hypodensity of white matter in parietal lobe of brain?\n",
      "hypodensity\n",
      "['hypo density', 'hypo-density', 'hypotenuse', 'hypotenuses', 'hedonist', 'hypnotist', 'hypertensive', \"hypotenuse's\"] \n",
      "\n",
      "\n",
      "Cochin to London etihad is the change over time of 1hr sufficient in Dubai?\n",
      "etihad\n",
      "['Erhard', 'ETD', 'egghead', 'towhead', 'airhead', 'etude', 'redhead', 'edited', 'Utahan', 'ahead', 'bedhead', 'eddied', 'oohed', 'Edward', 'edit', 'Deadhead', 'deadhead', 'Earhart', 'Godhead', 'edified', 'godhead', 'aided', 'atilt', 'edict', 'attired', 'editor'] \n",
      "\n",
      "\n",
      "Jawed habib haircut prices?\n",
      "habib\n",
      "['ha bib', 'ha-bib', 'habit', 'Harbin', 'hubbub', 'Bib', 'bib', 'nabob', 'Haber', 'Bob', 'HBO', 'bob', 'bub', 'hob', 'hub', 'harbor', 'hobnob', 'barb', 'hobby', 'hobo', 'hubby', 'Hobbs', 'hobbit', 'Bobbi', 'Heb', 'habitue', 'Barbie', 'babier', 'barbie', 'baobab', 'babe', 'baby', 'Hebe', 'herb', 'hobs', 'hubs', 'Huber', \"hob's\", \"hub's\", \"Haber's\"] \n",
      "\n",
      "\n",
      "Does any one have ebook of answers of wren and Martin grammer and composition?\n",
      "ebook\n",
      "['book', 'Bork', 'bock', 'Ebro', 'obj', 'Biko', 'Bioko', 'Ebola', 'Ebony', 'ebony', 'evoke', 'aback', 'oik', 'Beck', 'Bk', 'Booker', 'OK', 'beak', 'beck', 'berk', 'bk', 'bookie', 'oboe', 'biog', 'overbook', 'Reebok', 'yearbook', 'Eco', 'Ibo', 'bog', 'ebb', 'eek', 'ego', 'oak', 'elk', 'embark', 'ABC', 'Borg', 'Buck', 'EEOC', 'Eggo', 'Eyck', 'back', 'bark', 'boga', 'buck', 'eBay', 'ergo'] \n",
      "\n",
      "\n",
      "Does any one have ebook of answers of wren and Martin grammer and composition?\n",
      "grammer\n",
      "['crammer', 'grammar', 'grimmer', 'Grammy', 'Kramer', 'grimier', 'groomer'] \n",
      "\n",
      "\n",
      "What is [math]x[/math] if [math]x+\\left(\\dfrac{1}{x}\\right) =0[/math]?\n",
      "dfrac\n",
      "['Dirac', 'Draco', 'defrock', 'defray', 'Dvorak', 'drag', 'frag', 'Doric', 'Duroc', 'diffract', 'Africa', 'defraud', 'defrays', 'Drake', 'drake', 'freak', 'frock', 'track', 'Derick', 'drug', 'freq', 'frig', 'frog'] \n",
      "\n",
      "\n",
      "Whenever its about “her” its a very special feeling. Tried hard to forget her but she's alwys spcl. Should I stop talking to her even as a friend ?\n",
      "alwys\n",
      "['alleys', 'awls', 'ales', 'always', \"awl's\", \"ale's\", 'allays', 'alloys', \"ally's\", \"Al's\", 'Alas', 'alas', \"alley's\", 'alias', \"all's\", 'aloes', 'Alyssa', 'allows', 'ails', 'also', 'laws', 'lays', \"alloy's\", \"aloe's\", 'alts', 'owls', \"AOL's\", 'Alisa', 'Alyce', \"law's\", \"owl's\", \"Alar's\", 'Alps', \"Eloy's\", 'albs', 'ally', 'alms', 'alps', \"lay's\", \"alb's\", \"alp's\", \"Elway's\", \"Orly's\"] \n",
      "\n",
      "\n",
      "Whenever its about “her” its a very special feeling. Tried hard to forget her but she's alwys spcl. Should I stop talking to her even as a friend ?\n",
      "spcl\n",
      "['SPCA', 'Spock', 'speck', 'spec', 'spic', 'Spica', 'sepal', 'spell', 'spiel', 'spill', 'spoil', 'spool', 'suppl', 'specs', 'spics', \"spec's\"] \n",
      "\n",
      "\n",
      "My maths have become extremely weak and I am in class 12th. How can I improve my maths so that I can clear my JEE exams next year?\n",
      "th\n",
      "['Th', 'Thu', 'the', 'tho', 'thy', 'THC', 'Rh', 'HT', 'ht', 'H', 'T', 'h', 't', 'nth', 'Ch', 'OH', 'TA', 'Ta', 'Te', 'Ti', 'Tu', 'Ty', 'ah', 'ch', 'eh', 'oh', 'pH', 'sh', 'ta', 'ti', 'to', 'uh', 'DH', 'NH', 'TB', 'TD', 'TM', 'TN', 'TV', 'TX', 'Tb', 'Tc', 'Tl', 'Tm', 'tn', 'tr', 'ts', \"Th's\", \"T's\"] \n",
      "\n",
      "\n",
      "What is the name of the song in which picturized on Madhuri Dixit and Ranbir Kapoor and is from which movie?\n",
      "picturized\n",
      "['pictured', 'pictures', 'pasteurized', \"picture's\", 'factorized', 'cauterized'] \n",
      "\n",
      "\n",
      "What is the function of nucleoplasm in a plant cell?\n",
      "nucleoplasm\n",
      "['neoplasm', 'nucleolus', \"nucleolus's\"] \n",
      "\n",
      "\n",
      "Could CAT exam and MAT exam take place on same day (4th December 2016)?\n",
      "th\n",
      "['Th', 'Thu', 'the', 'tho', 'thy', 'THC', 'Rh', 'HT', 'ht', 'H', 'T', 'h', 't', 'nth', 'Ch', 'OH', 'TA', 'Ta', 'Te', 'Ti', 'Tu', 'Ty', 'ah', 'ch', 'eh', 'oh', 'pH', 'sh', 'ta', 'ti', 'to', 'uh', 'DH', 'NH', 'TB', 'TD', 'TM', 'TN', 'TV', 'TX', 'Tb', 'Tc', 'Tl', 'Tm', 'tn', 'tr', 'ts', \"Th's\", \"T's\"] \n",
      "\n",
      "\n",
      "Is government liasioning legal in India?\n",
      "liasioning\n",
      "['visioning', 'fashioning', 'rationing', 'loaning', 'cushioning', 'lining', 'cautioning', 'lashing', 'leaning', 'limning', 'lessening', 'loosening', 'motioning', 'chaining', 'learning', 'leashing', 'likening', 'livening', 'leavening', 'lightning'] \n",
      "\n",
      "\n",
      "Which is the best SSC and banking training insititute in Chandigarh?\n",
      "insititute\n",
      "['institute', 'instituter', 'instituted', 'institutes', 'instituters', \"institute's\", \"instituter's\"] \n",
      "\n",
      "\n",
      "Why does India sabotage and badmouth all economic projects which its neighbouring counries have in the world?\n",
      "neighbouring\n",
      "['neighboring', 'neighbored', 'Behring', 'boring', 'newborn', 'gibbering', 'numbering', 'neutering', 'nurturing', 'laboring', 'nibbling', 'burring', 'neuron', 'debarring', 'harboring', 'nickering', 'baring'] \n",
      "\n",
      "\n",
      "Why does India sabotage and badmouth all economic projects which its neighbouring counries have in the world?\n",
      "counries\n",
      "['countries', 'counties', 'cornrows', 'couriers', 'Canaries', 'canaries', 'curies', 'canneries', 'corries', 'cowries', 'curries', \"cornrow's\", 'coteries', \"courier's\", \"curie's\", \"Connie's\", \"cowrie's\", \"coterie's\"] \n",
      "\n",
      "\n",
      "When will moto G3 (Moto G 3rd gen 2015) get Android 7.0 (Nougat) update?\n",
      "moto\n",
      "['moot', 'mo to', 'mo-to', 'motor', 'motto', 'mot', 'Moro', 'moo', 'Mott', 'mote', 'mots', 'Moho', 'Soto', 'Toto', 'mono', 'moth', \"mot's\"] \n",
      "\n",
      "\n",
      "Prove that SNR of power = (SNR of voltage) sequare?\n",
      "sequare\n",
      "['square', 'squarer', 'secure', 'squire', 'squared', 'squares', 'Esquire', 'esquire', 'securer', 'Segre', 'Sucre', 'scare', \"square's\"] \n",
      "\n",
      "\n",
      "Why was cyrus mistry removed?\n",
      "cyrus\n",
      "['Cyrus', 'Cyprus', 'cirrus', 'Ceres', 'citrus', 'cerise', 'cruse', 'yrs', \"cry's\", 'syrups', 'Caruso', 'chorus', 'circus', 'Sirius', 'serous', \"Cr's\", 'Cruz', 'Grus', \"Sr's\", \"Zr's\", \"Cyprus's\", \"Ru's\", \"Syria's\", \"cirrus's\", \"Ceres's\", \"syrup's\"] \n",
      "\n",
      "\n",
      "Why was cyrus mistry removed?\n",
      "mistry\n",
      "['Misty', 'mastery', 'misty', 'mystery', 'misery', 'Mister', 'mister', 'moisture', 'musty', 'ministry', 'mist', 'mistral', 'history', 'misters', 'mistily', 'moistly', 'maestro', 'mists', \"mist's\", \"mister's\", \"Misty's\"] \n",
      "\n",
      "\n",
      "I am frightened of Arvind kejriwal, he may kill me, What shall I do?\n",
      "kejriwal\n",
      "['kraal', 'krill', 'Gujranwala', 'clerical', 'bejewel', 'crewel', 'Geritol', 'Jewel', 'crawl', 'jewel', 'scribal', 'Karol', 'Kigali', 'growl', 'rowel', 'Quirinal', 'mercurial', 'scrawl', 'Gabriela', 'Kringle', 'drywall', 'general', 'trowel', 'coral', 'gorilla', 'grill', 'Cornwall', 'firewall', 'guerrilla', 'corral', 'jackal', 'Cabral', 'karakul', 'caraway'] \n",
      "\n",
      "\n",
      "Is Bihar really developing under mahagathbandhan sarkar?\n",
      "mahagathbandhan\n",
      "[] \n",
      "\n",
      "\n",
      "Is Bihar really developing under mahagathbandhan sarkar?\n",
      "sarkar\n",
      "['Sakai', 'sarky', 'sake', 'Dakar', 'ska', 'Saar', 'sarge', 'Sara', 'starker', 'Saki', 'darker', 'sack', 'saga', 'scar', 'Sanka', 'seeker', 'Samar', 'Sarah', 'parka', 'sager', 'sugar', 'Barker', 'Parker', 'barker', 'marker', 'scalar', 'soak', 'sicker', 'sucker', 'Sakha', 'Saks', 'Stark', 'sacra', 'sear', 'snark', 'spark', 'stark', 'SK', 'Shaka', 'shark', 'sparkier', 'Asoka', 'skier', 'Ark', 'Serra', 'aka', 'ark', 'sparky', 'Osaka', 'SAC', 'sac', 'sag', 'Salk', 'Sask', 'sank', 'soar', 'Garza', \"ska's\"] \n",
      "\n",
      "\n",
      "Is the dynamic/flexi-pricing harsh on middle class people?\n",
      "flexi\n",
      "['flex', 'Felix', 'flax', 'flux', 'flecks', 'flexing', 'lxi', 'fleck', \"flex's\", 'flexed', 'flexes', 'Alexei', 'Alex', 'clxi', 'fleas', 'flees', \"fleck's\", \"flax's\", \"flea's\", \"flux's\"] \n",
      "\n",
      "\n",
      "How much do olympic gold medalists earn?\n",
      "olympic\n",
      "['Olympic', 'Olympics', 'Olympia', 'Olympiad', 'Olympian', 'Olympias', \"Olympia's\"] \n",
      "\n",
      "\n",
      "What is reactance in a capacitor?\n",
      "reactance\n",
      "['reluctance', 'reactant', 'reactants', \"reactant's\", 'remittance', 'radiance', 'reacting'] \n",
      "\n",
      "\n",
      "What are some math related working models for class 10th?\n",
      "th\n",
      "['Th', 'Thu', 'the', 'tho', 'thy', 'THC', 'Rh', 'HT', 'ht', 'H', 'T', 'h', 't', 'nth', 'Ch', 'OH', 'TA', 'Ta', 'Te', 'Ti', 'Tu', 'Ty', 'ah', 'ch', 'eh', 'oh', 'pH', 'sh', 'ta', 'ti', 'to', 'uh', 'DH', 'NH', 'TB', 'TD', 'TM', 'TN', 'TV', 'TX', 'Tb', 'Tc', 'Tl', 'Tm', 'tn', 'tr', 'ts', \"Th's\", \"T's\"] \n",
      "\n",
      "\n",
      "How do I know if my spouse is my soulmate?\n",
      "soulmate\n",
      "['soul mate', 'soul-mate', 'sulfate', 'simulate', 'sublimate', 'solute', 'cellmate', 'slate', 'palmate', 'schoolmate', 'summat', 'stalemate', 'slammed', 'slummed', 'Slater', 'Sumter', 'seatmate', 'sodomite', 'salute', 'slat'] \n",
      "\n",
      "\n",
      "How can I change my snapdeal account's mobile number?\n",
      "snapdeal\n",
      "['snap deal', 'snap-deal', 'sandal', 'snapped', 'sniped', 'Snapple', 'snidely', 'sundial', 'snappily', 'snipped', 'snooped', 'snippet', 'spatula', 'snippets', \"snippet's\"] \n",
      "\n",
      "\n",
      "Why is 'fahrenheit 451'  perceived as dystopia?\n",
      "fahrenheit\n",
      "['Fahrenheit', 'frenzied', 'freshet', 'freshest', 'forehead', 'frenetic', 'barrenest', 'frontier', 'front', 'Frenches', 'fringed', 'reheat', 'rennet', 'ferniest', 'freest', 'frenzies', 'Fronde', 'baronet', 'fainest', 'preheat', 'forewent', 'frequent', 'forehand', 'freehand'] \n",
      "\n",
      "\n",
      "Why is 'fahrenheit 451'  perceived as dystopia?\n",
      "dystopia\n",
      "['dustpan', 'stop', 'desktop', 'Dustin', 'doorstop', 'stoop', 'stoup', 'dust', 'distort', 'dustier', 'DST', 'Dusty', 'doorstops', 'dusty', 'despair', 'despot', 'dist', 'dost', 'step', 'despite', \"doorstop's\", 'stopper', 'doorstep', 'disport'] \n",
      "\n",
      "\n",
      "How do I define tasks vs milestones vs deliverables in an agile scrum methodology?\n",
      "deliverables\n",
      "['deliverable', \"deliverance's\", 'deliverance', 'deliveries', 'deliverers', \"deliverer's\"] \n",
      "\n",
      "\n",
      "Where can I buy meldonium in Canada?\n",
      "meldonium\n",
      "['melding', 'Melton', 'plutonium', 'millennium', 'melanoma', \"Melton's\", 'Miltonic', 'melodrama', 'Maldonado', 'melting', 'molding', 'Milton', 'molybdenum', 'moldings', 'platinum', \"molding's\", 'laudanum'] \n",
      "\n",
      "\n",
      "I accidentally took my blood pressure medicine twice, will I be ok?\n",
      "ok\n",
      "['OK', 'OJ', 'oak', 'oik', 'KO', 'OKs', 'pk', 'K', 'O', 'k', 'o', 'AK', 'UK', 'ox', 'wok', 'OE', 'OH', 'OR', 'ck', 'oh', 'oi', 'or', 'ow', 'wk', 'Bk', 'Gk', 'Mk', 'OB', 'OD', 'ON', 'OS', 'OT', 'Ob', 'Os', 'Oz', 'SK', 'bk', 'ob', 'of', 'om', 'on', 'op', 'oz', \"OK's\", \"O's\"] \n",
      "\n",
      "\n",
      "I and my girlfriends private partstouched each other.can she become pregenant?\n",
      "partstouched\n",
      "['parts touched', 'parts-touched', 'pastiches', 'pastiche', 'pastured', 'restitched', \"pastiche's\", 'psyched', 'stitched', 'starched', 'postured', 'persuaded', 'mustached', 'pastorate', 'presorted'] \n",
      "\n",
      "\n",
      "I and my girlfriends private partstouched each other.can she become pregenant?\n",
      "pregenant\n",
      "['pregnant', 'regnant', 'pregnancy', 'poignant', 'repugnant', 'preeminent'] \n",
      "\n",
      "\n",
      "Could we use cherenkov atmosphere radiation (with gamma rays or similar) to image the surface of a planet from here with ground based telescopes?\n",
      "cherenkov\n",
      "['Cerenkov', 'chronic', 'shrank', 'shrink', 'shrunk', 'shrinks', \"shrink's\", 'shrunken'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for q2 in train_df.question1.values:\n",
    "    i += 1\n",
    "    if i> 1000:\n",
    "        break\n",
    "    chkr.set_text(q2)\n",
    "    for err in chkr:\n",
    "        if not sum([c.isupper() for c in err.word]):\n",
    "            print(q2)\n",
    "            print(err.word)\n",
    "            print(chkr.suggest(err.word), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "# from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "GridSearchCV = sklearn.grid_search.GridSearchCV\n",
    "train_test_split = sklearn.cross_validation.train_test_split\n",
    "\n",
    "features = list(set(train_df.columns) - set(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate']))\n",
    "scaler = MinMaxScaler().fit(df[features])\n",
    "X = scaler.transform(df[features])\n",
    "#X = df[features]\n",
    "y = df['is_duplicate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "grid = {\n",
    "    'C': [1e-6, 1e-3, 1e0],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "cv = GridSearchCV(clf, grid, scoring='log_loss', n_jobs=-1, verbose=1)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.65004704695703419, 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = ['r', 'g', 'b', 'y', 'k', 'c', 'm', 'brown', 'r']\n",
    "lw = 1\n",
    "Cs = [1e-6, 1e-4, 1e0]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for different classifiers')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "labels = []\n",
    "for idx, C in enumerate(Cs):\n",
    "    clf = LogisticRegression(C=C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"C: {}, parameters {} and intercept {}\".format(\n",
    "        C, clf.coef_, clf.intercept_))\n",
    "    fpr, tpr, _ = roc_curve(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=lw, color=colors[idx])\n",
    "    labels.append(\"C: {}, AUC = {}\".format(C, np.round(roc_auc, 4)))\n",
    "\n",
    "plt.legend(['random AUC = 0.5'] + labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr, re, _ = precision_recall_curve(y_test, cv.best_estimator_.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(re, pr)\n",
    "plt.title('PR Curve (AUC {})'.format(auc(re, pr)))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentativi di Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_tagger(train_df, question, tagger):\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    train_df[tagger] = pd.Series(\n",
    "        Parallel(n_jobs=num_cores)(delayed(tag_phrase)(text)\n",
    "                                   for text in train_df[question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parallel_tagger(df, start, stop):\n",
    "    step = 10000\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    return Parallel(n_jobs=num_cores)(\n",
    "        delayed(sum_quests_and_tag)(df.loc[i:i+step])\n",
    "        for i in range(start, stop, step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proprietà transitiva: q è duplicata di B e anche di C allora B e C sono tra loro duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = train_df[train_df.is_duplicate == 1]\n",
    "\n",
    "qid1_qid2_dup = (df[['qid1',\n",
    "                     'qid2']].groupby('qid1')['qid2'].apply(list)).to_dict()\n",
    "qid2_qid1_dup = (df[['qid1',\n",
    "                     'qid2']].groupby('qid2')['qid1'].apply(list)).to_dict()\n",
    "\n",
    "\n",
    "def get_value_dict(d, v):\n",
    "    r = []\n",
    "    try:\n",
    "        r = d[v]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return r\n",
    "\n",
    "\n",
    "def get_qid_grouped(n_g):\n",
    "    qid_g = get_value_dict(qid1_qid2_dup, n_g).copy()\n",
    "    qid_g.extend(get_value_dict(qid2_qid1_dup, n_g))\n",
    "    while True:\n",
    "        temp = qid_g.copy()\n",
    "        for l in temp:\n",
    "            qid_g.extend(get_value_dict(qid1_qid2_dup, l))\n",
    "            qid_g.extend(get_value_dict(qid2_qid1_dup, l))\n",
    "        qid_g = list(set(qid_g))\n",
    "        if len(temp) == len(qid_g): break\n",
    "    return qid_g\n",
    "\n",
    "\n",
    "run_on_me = set(list(df.qid1) + list(df.qid2))\n",
    "group_dict = {}\n",
    "while len(run_on_me) != 0:\n",
    "    i = next(iter(run_on_me))\n",
    "    group_dict[i] = get_qid_grouped(i)\n",
    "    run_on_me = run_on_me - set(group_dict[i])\n",
    "\n",
    "# q1 and q2 are never the same question\n",
    "print(len(df[df.qid1 == df.qid2]))\n",
    "\n",
    "present_cases1 = set(\n",
    "    df[['qid1', 'qid2']].apply(axis=1, func=lambda x: (x['qid1'], x['qid2'])))\n",
    "present_cases2 = set(\n",
    "    df[['qid1', 'qid2']].apply(axis=1, func=lambda x: (x['qid2'], x['qid1'])))\n",
    "\n",
    "# check if there are duplicate q1-q2 pairs (q2-q1) -----> It tooked a long time, no duplicate pairs found\n",
    "# in the original dataframe\n",
    "# [j for j in present_cases if (j[1], j[0]) in present_cases] # ---> RESULT: []\n",
    "\n",
    "all_combo = []\n",
    "for ng in group_dict:\n",
    "    for i, l in enumerate(group_dict[ng]):\n",
    "        for j in group_dict[ng][i + 1:]:\n",
    "            all_combo.append((l, j))\n",
    "new_combo = list((set(all_combo) - set(present_cases1)) - set(present_cases2))\n",
    "\n",
    "print(\n",
    "    len(all_combo),\n",
    "    len(new_combo),\n",
    "    len(present_cases1), len(present_cases2), len(new_combo) / len(all_combo))\n",
    "\n",
    "\n",
    "\n",
    "dq = (df[['qid1', question1]].set_index('qid1',\n",
    "                                          drop=True)).to_dict()[question1]\n",
    "dq.update((df[['qid2', question2]].set_index(\n",
    "    'qid2', drop=True)).to_dict()[question2])\n",
    "\n",
    "new_df = pd.DataFrame(\n",
    "    list(map(lambda x: (x[0], x[1], dq[x[0]], dq[x[1]], 1), new_combo)),\n",
    "    columns=['qid1', 'qid2', question1, question2, 'is_duplicate'])\n",
    "\n",
    "train_df = pd.concat(axis=0, objs=[train_df, new_df])\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "train_df['id'] = train_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Check number of 1's in the test on the LB using logloss value for a fixed prediction probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## we use the fact that we know the logloss value of 0.37, user your value for a new try\n",
    "myp = 1\n",
    "mylogloss = 28\n",
    "p = [myp] * 10000\n",
    "l = np.array([log_loss([1] * r + [0] * (10000 - r), p) for r in range(1, 10000)])\n",
    "x = np.arange(0.01, 100, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e2e0a7240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, l, '_')\n",
    "plt.title('Log Loss vs. Pct. Positve with Constant Prediction of {}'.format(myp))\n",
    "plt.xlabel('% Positve in LB')\n",
    "plt.ylabel('Log Loss for Constant Prediction {}'.format(myp))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of 1 in prediction is: 0.19\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUS8nIJeRMTLKehFRLycgl5ExMv9HycZfw+jgf2wAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e2e1e5dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_check = pd.Series(data=np.abs(l - mylogloss), index=x)\n",
    "print('percentage of 1 in prediction is: {}'.format(x[int(df_check.argmin())]))\n",
    "df_check.plot();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creazione tagger_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger = pd.read_csv('/home/ale/random_program/Quora_double_question/risultato_tagger.csv', encoding='latin1')\n",
    "\n",
    "\n",
    "def recover_tagg_list(tag_string):\n",
    "    l = [\n",
    "        re.split(r'[\\'\\\"],\\s[\\'\\\"]', t[2:-1])\n",
    "        for t in tag_string[1:-2].split('], ')\n",
    "    ]\n",
    "    return l\n",
    "\n",
    "def tagged_ppf_verb(x):\n",
    "    app = recover_tagg_list(x)\n",
    "    return ([i[1] for i in app if len(i) > 1])\n",
    "\n",
    "\n",
    "tagger['new'] = tagger.apply(\n",
    "    axis=1, func=lambda x: Counter(tagged_ppf_verb(x['tagger'])))\n",
    "dizionario = tagger.set_index('quest_final')['new'].to_dict()\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open('./' + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('./' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "save_obj(dizionario, 'tag_counter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dizionario_max = pd.read_csv(\n",
    "    '/home/ale/random_program/Quora_double_question/tagged_list_counted_solved.csv',\n",
    "    sep=\";\",\n",
    "    encoding='latin1')\n",
    "dizionario_max = dizionario_max.set_index('name')['tag_recod'].to_dict()\n",
    "save_obj(dizionario_max, 'tag_max_freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltag = from_tag_tocluster(tagger[0:100]['tagger'].values)\n",
    "app = pd.DataFrame(alltag.groupby(['name', 'tag']).size()).reset_index()\n",
    "app.columns =['name','tag','count']\n",
    "app.to_csv('.\\\\taggestlist_count.csv',sep=\";\")\n",
    "\n",
    "def recodtag(x):\n",
    "    if x[0] == 'N':\n",
    "        return('NOUN')\n",
    "    elif x[0] == 'V':\n",
    "        return('VERB')\n",
    "    elif x[0] == 'J':\n",
    "        return('JJ')\n",
    "    else:\n",
    "        return(x)\n",
    "\n",
    "app['tag_recod'] = app.apply(axis=1, func = lambda x: recodtag(x.tag))\n",
    "app2 = pd.DataFrame(app.groupby(['name','tag_recod'])['count'].sum()).reset_index()\n",
    "app2.columns =['name','tag_recod','count']\n",
    "app3 = pd.DataFrame(app2.groupby(['name'])['count'].max()).reset_index()\n",
    "app3 = pd.merge(app3, app2, on =['name','count'])\n",
    "app3.to_csv('.\\\\tagged_list_counted_solved.csv',sep=\";\")\n",
    "app3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tuning w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The hyper-parameter choice is crucial for performance (both speed and accuracy):\n",
    "- architecture: skip-gram (slower, better for infrequent words) vs CBOW (fast)the training \n",
    "- algorithm: hierarchical softmax (better for infrequent words) vs negative sampling (better for frequent words, better with low dimensional vectors)\n",
    "- sub-sampling of frequent words: can improve both accuracy and speed for large data sets (useful values are in range 1e-3 to 1e-5)\n",
    "- context (window) size: for skip-gram usually around 10, for CBOW around 5\n",
    "- alpha is the initial learning rate (will linearly drop to min_alpha as training progresses).\n",
    "- min_count = ignore all words with total frequency lower than this.\n",
    "- negative = if > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20). Default is 5. If set to 0, no negative samping is used.\n",
    "- cbow_mean = if 0, use the sum of the context word vectors. If 1 (default), use the mean. Only applies when cbow is used.\n",
    "- iter = number of iterations (epochs) over the corpus. Default is 5.\n",
    "- batch_words = target size (in words) for batches of examples passed to worker threads (and thus cython routines). Default is 10000. \n",
    "- \n",
    "\n",
    "\n",
    "\n",
    "The model can be stored/loaded via its save() and load() methods, or stored/loaded in a format compatible with the original word2vec implementation via wv.save_word2vec_format() and KeyedVectors.load_word2vec_format().\n",
    "\n",
    "If you’re finished training a model (=no more updates, only querying), then switch to the gensim.models.KeyedVectors instance in wv\n",
    "\n",
    " word_vectors = model.wv\n",
    " del model\n",
    "to trim unneeded model memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train(m, win, s, sort, m_c, h):\n",
    "    print('New model:', m, win, s, sort, m_c, h)\n",
    "    model = word2vec.Word2Vec(\n",
    "        corpus,\n",
    "        size=s,\n",
    "        window=win,\n",
    "        min_count=m_c,\n",
    "        workers=4,\n",
    "        sorted_vocab=sort,\n",
    "        hs=h,\n",
    "        iter=10,\n",
    "        sg=m,\n",
    "        negative=10)\n",
    "\n",
    "    df = train_df[[q1, q2, 'is_duplicate']].copy()\n",
    "    tempvar = df.apply(\n",
    "        axis=1, func=lambda x: getback_function(pca_vars(x[q1], x[q2], model)))\n",
    "    tempvar.columns = ['diff_eigenv_pca', 'cos_pca', 'diff_ratio_ecc_pca']\n",
    "    #  + ['first_pca_'] + str(i) for i in range(0, model.vector_size + 1)\n",
    "    df = pd.concat([df, tempvar], axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    tempvar = df.apply(\n",
    "        axis=1,\n",
    "        func=\n",
    "        lambda x: getback_function(get_W2V_variables(x[q1], x[q2], model)))\n",
    "    tempvar.columns = [\n",
    "        'norm_mean_wv', 'norm_sum_wv', 'cos_mean_wv', 'cos_sum_wv'\n",
    "    ]\n",
    "    #  + ['vect_diff_'] + str(i) for i in range(0, model.vector_size + 1)\n",
    "    df = pd.concat([df, tempvar], axis=1)\n",
    "    df.replace(np.inf, np.nan, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    eventuali = [\n",
    "        'question1_clear_1', 'question2_clear_1', 'question1_clear_1_clear_2',\n",
    "        'question1_clear_1_clear_2', 'question2_clear_1_clear_2',\n",
    "        'question1_final', 'question2_final'\n",
    "    ]\n",
    "    features = list(\n",
    "        set(df.columns) -\n",
    "        set(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate'] +\n",
    "            eventuali))\n",
    "\n",
    "    x_train = df[features + ['is_duplicate']]\n",
    "\n",
    "    model_xgb, roc_auc_test, roc_auc_train, var_imp = train_xgboost(\n",
    "        x_train, features, 'is_duplicate', params, other_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#150 the best\n",
    "for s in [120, 135, 150, 165, 180]:\n",
    "    get_train(0, 5, s, 1, 5, 0)\n",
    "    \n",
    "for h in [0, 1]:\n",
    "    get_train(0, 5, 150, 1, 5, h)\n",
    "\n",
    "for sort in [-1, 1]:\n",
    "    get_train(0, 5, 150, sort, 5, 0)\n",
    "\n",
    "for m in [0, 1]:\n",
    "    win = 5 if m == 0 else 10\n",
    "    get_train(m, win, 150, 1, 5, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To speed up most_similar we can use a restriction in the vocab, restriction in the top most similarities don't help\n",
    "\n",
    "Find the top-N most similar words. Positive words contribute positively towards the\n",
    "similarity, negative words negatively.\n",
    "\n",
    "This method computes cosine similarity between a simple mean of the projection\n",
    "weight vectors of the given words and the vectors for each word in the model.\n",
    "The method corresponds to the `word-analogy` and `distance` scripts in the original\n",
    "word2vec implementation.\n",
    "\n",
    "If topn is False, most_similar returns the vector of similarity scores.\n",
    "\n",
    "`restrict_vocab` is an optional integer which limits the range of vectors which\n",
    "are searched for most-similar values. For example, restrict_vocab=10000 would\n",
    "only check the first 10000 word vectors in the vocabulary order. (This may be\n",
    "meaningful if you've sorted the vocabulary by descending frequency.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.most_similar('house', restrict_vocab=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data for cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_tag_tocluster(tagg_string):\n",
    "    non_for_cluster = ['SENT', '(', 'CD', ')', ',', ':', '``']\n",
    "    df_for_cluster = pd.DataFrame([(i[2], i[1])\n",
    "                                   for t in tagg_string\n",
    "                                   for i in recover_tagg_list(t) \n",
    "                                   if (len(i) == 3) and (i[1] not in non_for_cluster)])\n",
    "    df_for_cluster.columns = ['name', 'tag']\n",
    "    df_for_cluster.drop_duplicates(inplace=True)\n",
    "    df_for_cluster.reset_index(drop=True, inplace=True)\n",
    "    df_for_cluster['name'] = df_for_cluster.apply(axis=1, func=lambda x:x['name'].lower())\n",
    "    df_for_cluster.drop_duplicates(inplace=True)\n",
    "    return df_for_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_for_cluster = from_tag_tocluster( df['tagger'].values )\n",
    "df_for_cluster.to_csv('clusterizzami_sto_vocabolario.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_for_cluster = pd.read_csv('clusterizzami_sto_vocabolario.csv', encoding='latin1', usecols=range(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_verbs = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "tag_adverbs = ['RB','RBR','RBS']\n",
    "tag_adjective = ['JJ','JJR','JJS']\n",
    "tag_nouns = ['NN','NNS','NP','NPS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbs = df_for_cluster[df_for_cluster.apply(axis=1, func=lambda x:x['tag'] in tag_verbs)]['name']\n",
    "adverbs = df_for_cluster[df_for_cluster.apply(axis=1, func=lambda x:x['tag'] in tag_adverbs)]['name']\n",
    "adjective = df_for_cluster[df_for_cluster.apply(axis=1, func=lambda x:x['tag'] in tag_adjective)]['name']\n",
    "nouns = df_for_cluster[df_for_cluster.apply(axis=1, func=lambda x:x['tag'] in tag_nouns)]['name']\n",
    "\n",
    "verbs = verbs.drop_duplicates().reset_index(drop=True)\n",
    "adverbs = adverbs.drop_duplicates().reset_index(drop=True)\n",
    "adjective = adjective.drop_duplicates().reset_index(drop=True)\n",
    "nouns = nouns.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(verbs), len(adverbs), len(adjective), len(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'FW': 'Foreign word', --> variable has_foreign_word (and-or q1-q2)\n",
    "## potenzialmetne utile, da controllare meglio:\n",
    "'DT': 'Determiner',\n",
    "'MD': 'Modal',\n",
    "'SYM': 'Symbol',\n",
    "'UH': 'Interjection',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "def simple_distance(x_hx, y_hy, ix, iy):\n",
    "    hx, hy = x_hx[1][ix], y_hy[1][iy]\n",
    "    try:\n",
    "        xy_c = next(i for j in hx for i in hy if i == j)\n",
    "    except StopIteration:\n",
    "        return 1\n",
    "    n_x, n_y = len(hx), len(hy)\n",
    "    try:\n",
    "        return (((hx.index(xy_c) + 1) / n_x) + (\n",
    "            (hy.index(xy_c) + 1) / n_y)) / 2\n",
    "    except ValueError:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def noun_similarity(x, y, name_sin):\n",
    "    nhx = len(name_sin[x][1])\n",
    "    nhy = len(name_sin[y][1])\n",
    "    return min([\n",
    "        1 - simple_distance(name_sin[x], name_sin[y], ix, iy)\n",
    "        for ix in range(0, nhx) for iy in range(0, nhy)\n",
    "    ])\n",
    "\n",
    "\n",
    "def gethypernyms(x):\n",
    "    out = wn.synsets(x, lang='eng')\n",
    "    if len(out) != 0:\n",
    "        out = out[0]\n",
    "    else:\n",
    "        out = wn.synsets('entity', lang='eng')[0]\n",
    "    return (out, [l[::-1] for l in out.hypernym_paths()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myverbs = sorted( set(verbs.values) )\n",
    "name_sin = {k:gethypernyms(k) for k in myverbs}\n",
    "idx_name = {i:myverbs[i] for i in range(0,len(myverbs))} \n",
    "name_idx = {k:v for v,k in idx_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import time\n",
    "def symmetrize(a):\n",
    "    return a + a.T - np.eye(a.shape[0])\n",
    "\n",
    "def create_distance_matrix(name_sin, idx_name, mysimilarity):\n",
    "    start_time = time.time()\n",
    "    tot = len(idx_name)\n",
    "    l = [(d, row, col)\n",
    "         for row in range(0, tot)\n",
    "         for col in range(row, tot)\n",
    "         for d in [ mysimilarity(idx_name[row], idx_name[col], name_sin) ]\n",
    "         if d != 0]\n",
    "    df = pd.DataFrame(l, columns=['distance', 'row', 'col'])\n",
    "    data = list(df['distance'].values)\n",
    "    row = list(df['row'].values)\n",
    "    col = list(df['col'].values)\n",
    "    matrixd = symmetrize(sparse.csr_matrix((data, (row, col))).todense())\n",
    "    print('ho impiegato ' + str((time.time() - start_time) / 60) + ' minuti')\n",
    "    return 1 - matrixd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixd = create_distance_matrix(name_sin, idx_name, noun_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Clusters_helper import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in range(1,10):\n",
    "    print(\"Using {} min_samples\".format(m))\n",
    "    plot_eps_ncluster(matrixd, 0.1, 1, min_samples=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for eps in np.linspace(0.0001, 1, 10):\n",
    "    print(\"Using {} eps\".format(eps))\n",
    "    plot_minsamples_ncluster(matrixd, 0, 25, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for eps in np.linspace( 0.263231578947, 0.4, 20):\n",
    "    print(\"eps used: \", eps)\n",
    "    db = run_cluster(eps=eps, min_samples=3, X=matrixd)\n",
    "    if len(set(db.labels_)) == 1:\n",
    "        print('Only 1 cluster')\n",
    "        continue\n",
    "    print_silhouette(matrixd, db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group = pd.DataFrame(verbs, columns=['name'])\n",
    "\n",
    "X = matrixd\n",
    "db = run_cluster(eps=0.328016620498, min_samples=3, X=matrixd)\n",
    "update_group(db, group, name_idx)\n",
    "cluster = create_cluster_db(group, matrixd, name_idx)\n",
    "update_group2(group, name_idx, matrixd, cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ensamble stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_basic_vars.csv')\n",
    "test = pd.read_csv('test_basic_vars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_2 = pd.read_csv('test_isomap_isomappca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_final = pd.concat([test.set_index('test_id'), test_2.set_index('test_id')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventuali = [\n",
    "    'question1_clear_1', 'question2_clear_1', 'question1_clear_1_clear_2',\n",
    "    'question1_clear_1_clear_2', 'question2_clear_1_clear_2',\n",
    "    'question1_final', 'question2_final'\n",
    "]\n",
    "features = list(\n",
    "    set(train.columns) -\n",
    "    set(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate'] +\n",
    "        eventuali + ['dist_'+str(i) for i in range(0,10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_model = ['model_tuned' + str(i) for i in range(0, 5)]\n",
    "target = 'is_duplicate'\n",
    "xg_train = xgb.DMatrix(train[features])\n",
    "xg_test = xgb.DMatrix(test_final[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_preds_test = np.ones(len(test))\n",
    "xgb_preds_train = np.ones(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in xgb_model:\n",
    "    model = xgb.Booster({'nthread':4})\n",
    "    model.load_model(m)\n",
    "    xgb_preds_test += model.predict(xg_test)\n",
    "    print(m)\n",
    "xgb_preds_test /= len(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in xgb_model:\n",
    "    model = xgb.Booster({'nthread':4})\n",
    "    model.load_model(m)\n",
    "    xgb_preds_train += model.predict(xg_train)\n",
    "    print(m)\n",
    "xgb_preds_train /= len(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### submission xgboost\n",
    "submission = pd.DataFrame({'test_id': test['test_id'], 'is_duplicate': xgb_preds_test})\n",
    "submission.to_csv(\"submission_xgbfinal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN-xgb ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainNN = pd.read_csv('train_predsNN.csv')\n",
    "testNN = pd.read_csv('submissionNN.csv')\n",
    "testNN.set_index('test_id',inplace=True)\n",
    "trainNN.columns = ['preds_NN', 'is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_train_df = pd.DataFrame({'id': train['id'], 'preds_xgb': xgb_preds_train})\n",
    "xgb_train_df.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainNN['preds_xgb'] = xgb_train_df['preds_xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for alpha in np.linspace(0, 1, 10):\n",
    "    n = 'ens_'+str(alpha)\n",
    "    trainNN[n] = (1.-alpha)*trainNN['preds_NN'] + alpha*trainNN['preds_xgb']\n",
    "    trainNN[n+'_right'] = (trainNN[n] > 0.5) == trainNN['is_duplicate']\n",
    "    print(n, sum(trainNN[n+'_right'])/len(trainNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "225px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
